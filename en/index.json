[{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/5.01-workshop-overview/","title":"Workshop Overview","tags":[],"description":"","content":"OJT E-commerce Architecture OJT E-commerce is a modern serverless e-commerce platform built entirely on AWS. The architecture follows best practices for scalability, security, and cost optimization, replacing traditional Spring Boot backend with AWS Lambda functions.\nKey Components Frontend: React + Vite application hosted on S3 with CloudFront CDN Backend: Serverless API using API Gateway with 11 Lambda modules (63 endpoints) Database: RDS SQL Server Express 2019 in private subnet Storage: S3 buckets for images and frontend static files Authentication: JWT-based authentication with Cognito User Pool (optional) Security: VPC with public/private subnets, Security Groups, Secrets Manager Monitoring: CloudWatch Dashboard, Log Groups, and Alarms Architecture Diagram Workshop Flow This workshop follows a practical application development workflow:\nSetup Environment - Install tools (Node.js, AWS CLI, CDK CLI) CDK Bootstrap - Prepare AWS account for CDK deployments Deploy Core Infrastructure - VPC, RDS, S3, Cognito (NetworkStack, StorageStack, AuthStack, DatabaseStack) Deploy API Stack - API Gateway + Placeholder Lambda functions Deploy Lambda Code - Deploy actual Lambda function code (63 APIs) Deploy Frontend - Build React app and deploy to S3 + CloudFront Deploy Monitoring - CloudWatch Dashboard and Alarms Test Endpoints - Verify all 63 API endpoints work end-to-end Monitor \u0026amp; Maintain - Use CloudWatch for monitoring and debugging What You\u0026rsquo;ll Learn Infrastructure as Code with AWS CDK (TypeScript) Serverless architecture replacing Spring Boot with Lambda 2-step deployment strategy: Infrastructure + Lambda code separation RDS SQL Server in private subnet with Secrets Manager CloudFront CDN with Origin Access Control (OAC) JWT authentication with optional Cognito integration Lambda function modular organization (11 modules: Auth, Products, ProductDetails, Cart, Orders, Categories, Brands, Banners, Ratings, Users, Images) VPC design with NAT Gateway for private subnet internet access CloudWatch monitoring with Dashboard and Alarms Cost optimization strategies for development environment Realistic Cost Estimate Development Environment (Optimized):\nEstimated Monthly Cost: $44/month (60% reduction from original $111/month) Cost Breakdown:\nService Configuration Monthly Cost NAT Gateway 1 instance $23 RDS SQL Server t3.micro $15 Lambda 11 modules, 128MB $2 S3 Storage Images + Frontend $1.25 CloudFront CDN distribution $1.50 CloudWatch Dashboard + Logs $1.50 Total ~$44/month Cost Optimization Applied:\nRDS instance size: t3.small → t3.micro (saves $39/month) NAT Gateway: 2 → 1 instance (saves $23/month) Lambda memory: 256MB → 128MB (saves 50% per invocation) Lambda timeout: 30s → 10s (faster execution) Log retention: 7 days → 1 day (saves 85% CloudWatch cost) Backup retention: 7 days → 1 day for development Free Tier Benefits (First 12 months):\nLambda: 1M requests/month free S3: 5GB storage + 20K GET requests free RDS: t3.micro 750 hours/month free (single-AZ) Key Features E-commerce Platform: Products, Cart, Orders, Categories, Brands 63 API Endpoints: Complete CRUD operations for all modules Image Upload: S3 integration for product images Search \u0026amp; Filter: Products by category, brand, price range Order Management: Create, track, and manage orders Rating System: Product ratings and statistics Banner Management: Dynamic banners for promotions Admin Functions: User management, order status updates Lambda Modules Summary Module Functions Description Auth 4 Login, Signup, Logout, Me Products 12 CRUD, Search, Filter, Best-selling, Newest ProductDetails 7 CRUD, Images upload Cart 6 Add, Get, Update, Remove, Clear, Count Orders 9 CRUD, COD, Status, Date-range filter Categories 6 CRUD, Search Brands 5 CRUD Banners 7 CRUD, Toggle Ratings 3 Get, Stats, Create Users 3 GetAll, GetById, UpdateProfile Images 1 Upload to S3 Total 63 Deployment Strategy 2-Step Deployment Process:\nDeploy Infrastructure (CDK) - 5-10 minutes\nVPC, Subnets, NAT Gateway RDS SQL Server + Secrets Manager S3 Buckets (Images, Frontend) API Gateway + Placeholder Lambda Cognito User Pool (optional) Deploy Lambda Code - 1-2 minutes\nPackage Lambda functions with dependencies Upload to AWS Lambda Update function code independently Benefits of Separation:\nCDK deploy faster (no Lambda code build) No dependency resolution errors Update Lambda code independently (30 seconds) Clear separation: Infrastructure vs Application code CI/CD friendly deployment "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Summary: DX Talk #7 – Reinventing DevSecOps with AWS Generative AI Purpose of Attending the Event Understand the trend of AI in DevSecOps and the strategic shift in the enterprise. Learn the model of Generative AI integration into the entire software development process. Capture insights from real-life case studies of CMC Global and AWS. Orientate skills for DevSecOps Engineer in the context of high automation and security requirements. Speaker List Le Thanh Duc – Cloud Delivery Manager, CMC Global Du Quoc Thanh – Technical Leader, CMC Global Guest: Van Hoang Kha – Cloud Engineer, AWS Community Builder Highlights 1. Integrated AI solutions in DevSecOps Automate CI/CD pipeline and apply continuous security checks.\nPredict risks with AI and respond in real time.\nEliminate manual processes, reduce errors and bottlenecks.\n2. Case Study from CMC Global \u0026amp; AWS Analyze real DevSecOps processes with AI as the core.\nAutomate SAST/DAST, secret scanning, IaC validation.\nLessons on implementing AI in large-scale enterprises.\n3. DevSecOps career orientation Shift-left Security mindset throughout the entire SDLC.\nImportant skills: CI/CD, IaC, automation, cloud security, GenAI.\nThe role of AI in improving development speed and quality.\nWhat We Learned 1. Integrating AI \u0026amp; Automation Understanding the AI-Driven DevSecOps model with the ability to analyze risks, automate security testing and intelligent monitoring.\nAI shortens the time to detect and handle incidents, improving system safety.\n2. Modern DevSecOps mindset Security must be integrated into the entire software development lifecycle. Tools to master: Jenkins/GitLab CI – CI/CD automation SonarQube – SAST OWASP ZAP – DAST Terraform – IaC and automated infrastructure management 3. Generative AI Tools Learn Amazon Q Developer with the following capabilities: Generate code Write tests Detect vulnerabilities Optimize DevSecOps workflow on AWS Apply to Work (Worklog Week 6) Integrate DevSecOps thinking into ongoing projects. Research and test Amazon Q Developer in the code review process. Add SAST/DAST to CI/CD pipeline. Optimize IaC with automated rules and policies. Event Experience Expert Perspective Hear practical sharing about deploying Generative AI in large enterprise systems.\nUnderstand how AI helps reduce operational and security workload.\nThe value of AI Eliminate many manual tasks and reduce dependence on gatekeepers.\nIncrease automation and scalability of the system.\nPersonal orientation Need to continuously update on Cloud, AI and security.\nFocus on learning deeply on AWS Security and DevSecOps practices.\nConclusion The event provides an overview and practice of DevSecOps combined with Generative AI, providing clear direction for technology engineers in improving capacity and applying it to practical projects on AWS. This is an important resource for developing DevSecOps skills in a modern environment.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Dương Minh Đức\nPhone Number: 0786579568\nEmail: duongduc0786@gmail.com\nUniversity: FPT University\nMajor: Information security\nClass: AWS082025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 12/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members\n- Read and take note of internship unit rules and regulations - find companions and set up the Furious Five group 09/08/2025 09/08/2025 3 - Learn about AWS and its types of services + Compute + Storage + Networking + Database + Batch 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Create AWS Free Tier account\n- Learn about AWS Console \u0026amp; AWS CL\n- Practice: + Create AWS account + Install \u0026amp; configure AWS CLI + How to use AWS CLI 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn basic EC2: + Instance types + AMI + EBS - SSH connection methods to EC2 - Learn about Elastic IP 09/11/2025 09/11/2025 https://cloudjourney.awsstudygroup.com/ 6 -Practice: + Launch an EC2 instance + Connect via SSH + Attach an EBS volume 09/12/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ Week 1 Achievements: Understood what AWS is and mastered the basic service groups:\nCompute Storage Networking Database Security, Identity \u0026amp; Compliance Analytics Machine Learning \u0026amp; AI Management \u0026amp; Monitoring Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region Used AWS CLI to perform basic operations such as:\nCheck account information and identity access. Manage S3 storage services: create buckets, list buckets, upload and download data. Manage EC2: create, start, stop, list, and describe instances. Manage RDS: list and describe databases. Manage IAM: create and assign permissions for users, groups, and roles. Manage VPC: view and describe VPCs, subnets, security groups. Monitor the system using CloudWatch: view logs, metrics. Manage Route 53: list hosted zones, record sets. Manage Lambda: deploy and invoke Lambda functions. Manage CloudFormation: deploy and monitor stacks. "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Nomalab Automates Ad Break Detection in Media Workflows with AWS by Thomas Buatois, Iryna Oliinykova, and Ken Shek on 04 APR 2025 in Amazon Bedrock, Amazon Machine Learning, Amazon OpenSearch Service, Amazon Rekognition, Amazon Transcribe, Analytics, Artificial Intelligence, AWS Elemental MediaConvert, Data Science \u0026amp; Analytics for Media, Generative AI, Media \u0026amp; Entertainment, Media Services, Media Supply Chain \u0026amp; Archive, Monetization\nThe Media and Entertainment (M\u0026amp;E) industry is undergoing an unprecedented transformation, with the volume and complexity of content continuing to grow at a rapid pace. To stay competitive, broadcasters and publishers must find innovative solutions to optimize their media workflows from ingest to delivery. Recognizing this challenge, Nomalab, a leading cloud-based media management platform available on the AWS Marketplace, has leveraged the power of AI and Generative AI through the Guidance for Media2Cloud on AWS (Media2Cloud). Media2Cloud is an open-source, serverless framework that exemplifies how embracing the latest cloud and AI technologies can drive efficiency and position media organizations for long-term success. This post explores how Nomalab’s innovative use of AWS services and generative AI is transforming media workflows and setting a new standard for content processing efficiency.\nNomalab Use Case Nomalab’s customers—including major media groups—face increasing demand to deliver more content to linear TV and OTT platforms than ever before. Automation has become essential for maintaining a competitive edge in viewer experience and operational efficiency. A key pain point in the content delivery pipeline is the generation of segmentation metadata for long-form content, particularly identifying title sequences, end credits, and ad insertion points that respect narrative flow. The goal was to create a system that accurately generates metadata without human intervention, dramatically accelerating content preparation and reducing costs. “Our clients need to be able to insert ads seamlessly into their programming, but manually reviewing hours of footage to identify suitable ad breaks is extremely time-consuming,” explains Romane Lafon, Digital Media CTO at Nomalab. “We knew AI could be the answer, but we wanted a solution that was highly accurate and cost-effective to run at scale.” To meet stringent quality standards, Nomalab targeted over 90% accuracy in identifying segmentation points—matching or exceeding human-level performance. This gave clients the confidence to fully adopt automated workflows.\nIntegrating Media2Cloud and Generative AI When faced with automating ad break detection, Nomalab turned to Media2Cloud. The framework not only simplifies the migration of video assets and metadata to AWS but also unlocks deeper content insights by leveraging AI-powered metadata extraction. “By integrating Media2Cloud and advanced AI capabilities, we’ve been able to develop a uniquely powerful solution that automates key tasks and delivers measurable results for our clients,” says Lafon.\nHow It Works Media2Cloud uses a combination of traditional AI/ML and generative AI to detect natural content breaks—known as chapter points—where visual and narrative contexts shift. Step 1: Visual Shot Detection The process starts with the Amazon Rekognition Segment API, which provides frame-accurate camera shot detection and technical cue identification (e.g., color bars, black frames, end credits).\nStep 2: Grouping Shots into Scenes Detected shots are regrouped into logical scenes using the Amazon Titan Multimodal Embedding model via Amazon Bedrock. Frames are converted into vector embeddings capturing semantic meaning, stored in Amazon OpenSearch Service using K-NN indexing to cluster similar frames together.\nStep 3: Analyzing Conversation Flow Next, Amazon Transcribe converts speech to text with timestamps, and Amazon Bedrock analyzes conversation flow to identify topic transitions, helping create natural chapter breaks aligned with visual cues.\nStep 4: Aligning Audio and Visual Cues By aligning detected scenes with dialogue transitions, the workflow identifies natural, unobtrusive ad break opportunities—points where commercial interruptions are least disruptive to the viewer experience.\nPlacing Ad Breaks Building on this foundation, Media2Cloud’s ad break detection feature pinpoints frame-accurate opportunities for ad placement while generating contextual metadata using IAB Content Taxonomy V3 and GARM Taxonomy.\nThis contextual layer enables ad decision servers to make intelligent placement choices based on the surrounding content.\nIntegration Nomalab extends Media2Cloud with a proprietary post-evaluation phase that mirrors human decision-making. Custom business rules refine and prioritize ad break opportunities, ensuring only the most relevant and strategic breaks are selected. This transforms raw detection data into production-grade insights, delivering optimal ad placement while maintaining the integrity of the viewing experience.\nFigure 6 – Nomalab’s analysis workflow integrating AWS services and proprietary post-evaluation logic. “The integration with Media2Cloud was critical,” says Lafon. “It provided a scalable, cloud-native foundation so we could focus on AI-powered features that deliver real value. The generative AI capabilities of Amazon Bedrock were a game-changer—combining computer vision, speech-to-text, natural language understanding, and business rules to reach near-human accuracy.”\nBenefits and Results By automating ad break detection, Nomalab has drastically improved workflow efficiency. A manual operator could handle about 25 programs per day; now, with AWS automation, entire libraries can be analyzed in hours—at scale and with consistent accuracy. “Our overall target is a 90 percent or higher accuracy rate, and we are nearly there or higher depending on content type,” says Lafon. “The best part is, our clients don’t have to worry about the complexity—they simply receive fully enriched media assets ready for ingest and distribution.” Scalability is another key benefit: “We handle tens of thousands of content pieces per year while keeping costs under control,” adds Lafon. “It’s a win-win for us and our clients.”\nLooking to the Future As the media industry evolves, Nomalab’s workflow highlights how AWS and generative AI are transforming media operations. “This is just the beginning,” Lafon says. “We’re already exploring automation for content classification, metadata enrichment, and even media quality control. The potential is limitless.” By combining Amazon Bedrock, Amazon Rekognition, and Amazon Transcribe, Nomalab demonstrates the power of uniting AI and cloud technologies to achieve human-level accuracy in automated workflows. This synergy between foundational AI/ML services and generative AI unlocks new insights from media assets—setting a new benchmark for automation in the media industry. Looking ahead, as cloud-based AI continues to evolve, these technologies will drive increasingly intelligent, automated content-processing pipelines—becoming a key differentiator for competitive media organizations. For media companies seeking to future-proof operations, Nomalab’s success on AWS demonstrates what’s possible by embracing the latest innovations in AI, cloud computing, and generative AI—transforming media workflows for the digital era.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Optimize Multimodal Search Using the TwelveLabs Embed API and Amazon OpenSearch Service by James Le, Gitika Vijh, and Kruthi Jayasimha Rao on 04 APR 2025 in Advanced (300), Amazon OpenSearch Service, Partner Solutions\nThe exponential growth of video content has created both opportunities and challenges. Content creators, marketers, and researchers are now faced with the daunting task of efficiently searching, analyzing, and extracting valuable insights from vast video libraries. Traditional keyword-based search methods often fall short when analyzing visual, audio, or contextual elements within videos—making it difficult for organizations to unlock the full potential of their multimedia assets. By integrating TwelveLabs’ Embed API with Amazon OpenSearch Service, we can now interact with and derive insights directly from video content. TwelveLabs’ advanced AI-powered video understanding technology, combined with OpenSearch’s vector database and analytics capabilities, enables multimodal video discovery with deep contextual understanding. This post demonstrates how to integrate the TwelveLabs Embed API with OpenSearch Service to build a multimodal search solution. You’ll learn how to:\nGenerate rich, contextual embeddings from video content.\nStore and index these embeddings in OpenSearch.\nEnable search capabilities across text, image, and audio modalities.\nBy the end, you’ll understand how to implement a system that can transform how your organization handles and extracts value from video content.\nTwelveLabs is an AWS Advanced Partner and AWS Marketplace Seller specializing in video understanding solutions. Its Embed API transforms raw video content into meaningful, searchable data using state-of-the-art machine learning models. Each video is converted into a 1024-dimensional dense vector embedding, representing the core semantic features across multiple modalities—image, text, and audio.\nKey Features of TwelveLabs Embed API Multimodal understanding – Generates embeddings that capture visual expressions, body language, spoken words, and overall context.\nTemporal coherence – Models the relationships between modalities over time for accurate contextual representation.\nFlexibility – Processes all modalities (video, text, audio) natively without separate models.\nHigh performance – Uses a video-native approach for superior temporal and contextual coherence.\nBenefits and Use Cases The Embed API provides several advantages for businesses and developers working with video content: Enhanced Search Capabilities – Perform multimodal search across video libraries using text, audio, or images.\nContent Recommendation – Improve recommendation accuracy through contextual similarity between videos.\nScene Detection and Segmentation – Automatically detect and segment scenes for easier analysis.\nContent Moderation – Efficiently identify inappropriate content across large datasets.\nCommon use cases include: Anomaly detection\nSentiment analysis\nDiversity sorting\nSmart content recommendations\nArchitecture Overview The architecture integrates TwelveLabs Embed API and Amazon OpenSearch Service to enable advanced multimodal search. It consists of:\nTwelveLabs Embed API – Generates 1024-dimensional vector embeddings from video content, capturing multimodal relationships. Amazon OpenSearch Service (Vector Database) – Stores and indexes embeddings for vector-based search. AWS Secrets Manager – Stores API keys, OpenSearch credentials, and access secrets securely. Integration Components – TwelveLabs SDK and OpenSearch Client for processing videos, generating embeddings, and indexing data. he Use Case In the demo, two example videos are used:\nRobin bird forest video by Federico Maderno\nIsland video by Bellergy RC\nHowever, this same architecture applies to other use cases such as:\nSearching thousands of hours of archival news footage.\nAutomating metadata tagging for complex visual and audio context.\nPerforming cross-modal queries (text, image, or audio to video).\nRapid retrieval of relevant clips for breaking news or highlights.\nBy integrating TwelveLabs Embed API with OpenSearch Service, organizations can:\nGenerate 1024-dimensional embeddings that capture video content, audio cues, and on-screen text.\nEnable text-to-video, image-to-video, and audio-to-video search.\nReduce retrieval time from hours to seconds.\nSolution Walkthrough Step 1 – Set Up the TwelveLabs SDK Obtain your TwelveLabs API Key.\nStore it in AWS Secrets Manager (e.g., under TL_API_KEY).\nUse the AWS SDK to retrieve and use it in your Python environment.\nStep 2 – Generate Video Embeddings Use the Embed API to create multimodal embeddings. The model (Marengo-retrieval-2.7) processes video, capturing interrelations between image, text, and audio. Embeddings are asynchronous to generate and represent rich, time-aware features.\nStep 3 – Configure Amazon OpenSearch Install opensearch-py, botocore, and requests-aws4auth.\nAuthenticate with your OpenSearch domain using stored credentials.\nVerify the connection and retrieve cluster information.\nStep 4 – Create a Vector Index Define an index with a 1024-dimensional knn_vector field for similarity search. This enables fast k-nearest neighbor (kNN) queries against video embeddings.\nStep 5 – Ingest Embeddings into OpenSearch Once embeddings are generated, ingest them into the index using the bulk API. Each document stores: The video title\nSegment start and end times\nThe embedding vector\nStep 6 – Perform Vector Search Run vector-based search queries to find the most similar embeddings using: def search_similar_segments(query_vector, k=5):\nquery = { \u0026#34;size\u0026#34;: k, \u0026#34;query\u0026#34;: { \u0026#34;knn\u0026#34;: { \u0026#34;embedding_field\u0026#34;: { \u0026#34;vector\u0026#34;: query_vector, \u0026#34;k\u0026#34;: k } } } } This function retrieves the top k video segments most similar to a given query vector.\nStep 7 – Text-to-Video Search Convert a text query (e.g., “Bird eating food”) into a vector embedding using TwelveLabs’ text embedding model, then perform a kNN search in OpenSearch. Results return: Video name\nTime range\nSimilarity score\nStep 8 – Audio-to-Video Search Use TwelveLabs’ audio embedding capabilities to convert an audio clip (e.g., “Rock 808 beat.mp3”) into a vector. Perform vector search to retrieve video clips with matching audio characteristics.\nStep 9 – Image-to-Video Search Use an image (e.g., Ocean Image by shotbyjagar) to generate embeddings and perform image-to-video matching. Visually similar scenes are retrieved based on shape, color, and composition features encoded in the embedding.\nResults and Insights Each search returns a ranked list of relevant video segments, including similarity scores and timestamps. Examples: Text query: “Bird eating food” retrieves segments from the robin-bird.mp4 video.\nImage query: An ocean image retrieves high-scoring segments from the island.mp4 video.\nAudio query: A rhythmic track retrieves visually synchronized video clips.\nThis enables cross-modal video retrieval with human-like semantic understanding.\nCleanup To avoid incurring costs, delete: The OpenSearch Service domain.\nAny S3 buckets, Secrets, and Lambda functions created.\nConclusion The integration of TwelveLabs Embed API with Amazon OpenSearch Service delivers a powerful, scalable solution for multimodal video search and analysis. By combining TwelveLabs’ video-native embeddings with OpenSearch’s vector search capabilities, you can perform text-to-video, image-to-video, and audio-to-video searches—unlocking contextual insights that traditional methods can’t match. This approach empowers developers and organizations to: Enhance video search and discovery.\nImprove user engagement with intelligent content retrieval.\nEnable advanced analytics across massive multimedia datasets.\nAs industries increasingly rely on video for communication, learning, and marketing, multimodal AI search will be a key differentiator in managing and understanding large video archives.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Optimizing Network Footprint in Serverless Applications by Chris McPeek on 21 MAR 2025 in Amazon API Gateway, Amazon Elastic Kubernetes Service, Amazon EventBridge, Amazon Simple Queue Service (SQS), Amazon Simple Storage Service (S3), AWS Lambda, Serverless\nAuthored by Anton Aleksandrov, Principal Solutions Architect, AWS Serverless and Daniel Abib, Senior Specialist Solutions Architect, AWS.\nServerless application developers frequently encounter scenarios where they must transport large payloads, particularly in modern cloud applications that require rich data. Examples include analytics platforms generating detailed reports, e-commerce systems managing large product catalogs, healthcare applications transmitting patient records, or financial services aggregating extensive transactional data. However, many serverless services have strict payload size limits — for example: AWS Lambda: 6 MB per request/response\nAmazon SQS and Amazon EventBridge: 256 KB per message\nThis post explains how to use data compression techniques to reduce network footprint and transport larger payloads within existing constraints.\nOverview As cloud applications evolve to meet new features and Service Level Objectives (SLOs), payload sizes often grow. Eventually, you may hit service-imposed limits such as: Lambda synchronous invoke: 6 MB\nAPI Gateway: 10 MB\nSQS/EventBridge: 256 KB\nIf payloads reach tens of MBs or include large binary objects, you can store data on Amazon S3 and use pre-signed URLs for direct upload/download.\nFigure 1 – Sample architecture for handling large payloads. When handling large messages via SQS or EventBridge, you can store message content in S3 and send only a reference. The consumer then retrieves the full message directly from S3. However, while these techniques work, they introduce architectural complexity and require modifying existing workflows. Additionally, as payload sizes increase, data transfer costs rise—especially through NAT Gateways, VPC Endpoints, or cross-Region transfers. For example, Lambda functions inside a VPC may invoke public endpoints or external services.\nFigure 2 – Examples of using virtual network appliances with serverless applications. Both NAT Gateway and VPC Endpoint are billed per GB of data processed, making data compression a valuable optimization technique.\n**What Is Data Compression? Data compression reduces data size to improve performance and cost-efficiency for storage and transmission. Tools such as gzip and zstd are widely used, standardized under IANA and IETF RFC 9110. Modern browsers (Chrome, Firefox), HTTP tools (curl, Postman), and runtimes (Node.js, Python) support compression natively. When clients send compressed data, they specify it using the Content-Type header. To receive compressed responses, clients specify supported compression methods in the Accept-Encoding request header.\nFigure 3 – Accept-Encoding request header specifying supported compression methods. The server then compresses responses using a supported method and includes a Content-Encoding header to indicate the compression type.\nFigure 4 – Content-Encoding response header specifying compression method. This reduces bytes transmitted over the network, improving latency. Text-based formats like JSON, XML, HTML, and YAML compress well, whereas binary files (PDF, JPEG) compress less effectively.\nData Compression with API Gateway Amazon API Gateway offers built-in compression via the minimumCompressionSize configuration, which automatically compresses responses above a certain size (0 bytes–10 MB).\nFigure 5 – Handling data compression in API Gateway. How It Works API Gateway automatically decompresses incoming requests and compresses outgoing responses.\nCompression is bi-directional and works seamlessly with JSON payloads.\nClients specify compression in the Content-Encoding header; API Gateway decompresses before forwarding to integrations.\nAPI Gateway compresses integration responses when clients include a matching Accept-Encoding header.\nTest results: Compression disabled: Response size = 1 MB, latency = 660 ms\nCompression enabled: Response size = 220 KB, latency = 550 ms\n→ 78% network footprint reduction and 110 ms faster response. To preserve compression end-to-end (so Lambda can handle decompression), configure binaryMediaTypes to allow binary passthrough.\nHandling Compressed Data in AWS Lambda AWS Lambda Invoke API supports text-based payloads (e.g., JSON) up to 6 MB (sync) or 256 KB (async). You can, however, compress payloads within Lambda code to overcome limits and reduce transfer costs.\nFigure 7 – Transporting compressed payloads in serverless applications. The code below shows how to compress response payloads in Node.js using the built-in zlib module:\nFigure 8 – Sample code implementing response payload compression in a Lambda function. Key details: Line 1 imports gzip from the zlib module.\nLines 11 compress and Base64-encode data (since Lambda expects text-based output).\nLines 13–21 create the response object with isBase64Encoded=true and proper headers.\nResult: A 20 MB uncompressed JSON returns as a 2.5 MB compressed payload — 80% network footprint reduction.\nFigure 9 – Screenshot from Postman showing original vs. compressed payload size. This method allows transferring payloads several times larger than Lambda’s default limits\nUsing Function URLs with Compressed Payloads Transporting compressed payloads via Lambda Function URLs requires no extra configuration. The handler simply compresses and Base64-encodes the response. Incoming requests marked as binary are automatically passed to your function as Base64 strings.\nFigure 10 – Sample code implementing request payload decompression in a Lambda function.\nTrade-Offs and Testing Results Compression is CPU-intensive, increasing invocation duration and potentially cost. However, it reduces data transfer and latency—often yielding net savings. Tests using Node.js on ARM architecture with random JSON payloads showed: Compressing a 1 MB JSON object added ~124 ms compute time for 1 GB memory.\n10 million invocations → +$16 compute cost.\nBut 70% payload size reduction saved ~$300 (NAT Gateway) or ~$70 (VPC Endpoint).\nSavings depend on payload type and compression ratio. For low-compressibility data, results may vary.\nSample Application You can test this in your own AWS account using the sample project in the provided GitHub repository. The sample provisions two Lambda functions to demonstrate gzip compression for GET and POST operations via Function URLs and API Gateway. Results show \u0026gt;80% reduction in network footprint using JSON payloads.\nFigure 11 – Screenshot from Postman showing the original and compressed payload size.\nConclusion Data compression allows larger payload transfers and significantly reduces network footprint. It improves latency and helps control transfer costs, especially for data flowing through NAT Gateways or VPC Endpoints. However, compression adds CPU overhead — you should balance the compute cost against the network savings. Compression is most effective for large text-based payloads, where small increases in compute time are offset by faster, cheaper data transfer. By applying these techniques in AWS Lambda and API Gateway, you can make your serverless applications more efficient, scalable, and cost-optimized.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/","title":"Worklog","tags":[],"description":"","content":"On this page, you will need to introduce your worklog. How did you complete it? How many weeks did you take to complete the program? What did you do in those weeks?\nTypically, and as a standard, a worklog is carried out over about 3 months (throughout the internship period) with weekly contents as follows:\nWeek 1: Getting acquainted with AWS and basic services in AWS\nWeek 2: Learn basic services in AWS 2\nWeek 3: Learn basic services in AWS 3\nWeek 4: Learn basic services in AWS 4\nWeek 5: Attend the event and start the first steps of the sales web project\nWeek 6: Learn AWS services and gradually connect with the sales web project\nWeek 7: Learn AWS services and review mid-term\nWeek 8: Learn more about AWS services and review practice\nWeek 9: Progress with great strides of the Sales Web Project\nWeek 10: Understand and apply AWS to the Sales Web Project\nWeek 11: Understand and apply AWS to the Sales Web Project 2\nWeek 12: Understand and apply AWS to the Sales Web Project 3\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/5.02-setup-environment/","title":"Setup Environment","tags":[],"description":"","content":"Overview In this step, you will install all the necessary tools to develop and deploy the OJT E-commerce application.\nRequired Tools 1. Node.js 20.x\n# Download from https://nodejs.org/ # Or use nvm (recommended) nvm install 20 nvm use 20 # Verify installation node --version # Should be v20.x npm --version ![Node.js Installation] Screenshot: Terminal showing Node.js 20.x installed\n2. AWS CLI v2\n# Windows: Download from https://aws.amazon.com/cli/ # macOS: brew install awscli # Linux: curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install # Verify installation aws --version ![AWS CLI Installation] Screenshot: Terminal showing AWS CLI v2 installed\n3. AWS CDK CLI\n# Install CDK globally npm install -g aws-cdk # Verify installation cdk --version ![CDK CLI Installation] Screenshot: Terminal showing CDK CLI installed\n4. Git\n# Download from https://git-scm.com/ # Or use package manager # Verify installation git --version ![Git Installation]\n5. Code Editor\nRecommended: Visual Studio Code with extensions:\nAWS Toolkit GitLab Workflow ESLint Prettier AWS Account Setup 1. Create AWS Account\nIf you don\u0026rsquo;t have an AWS account:\nGo to https://aws.amazon.com/ Click \u0026ldquo;Create an AWS Account\u0026rdquo; Follow the registration process Add payment method 2. Create IAM User\nFor security, don\u0026rsquo;t use root account\nGo to IAM Console → Users → Create user Create user and save credentials ![IAM User Created] Screenshot: IAM console showing user created with AdministratorAccess\n3. Configure AWS CLI\n# Configure AWS credentials aws configure # Enter: # AWS Access Key ID: [Your Access Key] # AWS Secret Access Key: [Your Secret Key] # Default region name: ap-southeast-1 # Default output format: json ![AWS CLI Configure] Screenshot: Terminal showing aws configure completed\n4. Verify AWS Access\n# Test AWS credentials aws sts get-caller-identity # Should return your account ID and user ARN ![AWS Access Verified]\nDomain Setup (Optional) If you want to use a custom domain:\n1. Register Domain\nBuy domain name on hpanel.hostinger Route 53 creates dns record to hostinger For this workshop, we use: yourdomain.com\n2. Note Domain Registrar\nYou\u0026rsquo;ll need access to domain registrar to update nameservers later.\nGitLab Setup Create GitLab Repo\n3. Configure Git\n# Set your name and email git config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email \u0026#34;your.email@example.com\u0026#34; # Verify configuration git config --list Project Setup 1. Clone or Create Project\nOption A: Clone existing project\ngit clone https://gitlab.com/your-username/ojt-ecommerce.git cd ojt-ecommerce Option B: Create new project\nmkdir OJT cd OJT git init 2. Project Structure\nThe OJT E-commerce project has the following structure:\nOJT/ ├── OJT_infrastructure/ # CDK Infrastructure (TypeScript) │ └── Deploy AWS resources: VPC, RDS, S3, API Gateway, etc. │ ├── OJT_lambda/ # Lambda Functions (JavaScript) - 63 APIs │ └── Application code for API endpoints │ ├── OJT_frontendDev/ # Frontend (React + Vite) │ └── Web application │ └── database/ # Database Scripts (MySQL) ├── schema/ # Main schema ├── migrations/ # Migration scripts └── seeds/ # Sample data 3. Install Dependencies\n# Install CDK Infrastructure dependencies cd OJT_infrastructure npm install # Install Lambda dependencies cd ../OJT_lambda npm install npm run install:all # Install Frontend dependencies cd ../OJT_frontendDev npm install 4. Copy Environment Variables\nFor CDK Infrastructure:\ncd OJT_infrastructure cp .env.example .env Edit .env with your values:\n# AWS Configuration AWS_ACCOUNT_ID=123456789012 AWS_REGION=ap-southeast-1 # Database Configuration DB_NAME=demoaws DB_USERNAME=admin DB_PASSWORD=YourSecurePassword123! # Application Configuration APP_NAME=OJT-Ecommerce ENVIRONMENT=dev # JWT Secret JWT_SECRET=your-super-secret-jwt-key-change-this-in-production For Lambda:\ncd ../OJT_lambda cp .env.example .env Edit .env with your values:\n# AWS Configuration AWS_REGION=ap-southeast-1 AWS_ACCOUNT_ID=your-account-id # JWT Configuration JWT_SECRET=your-jwt-secret-key JWT_EXPIRES_IN=7d Verification Check that everything is installed correctly:\n# Check Node.js node --version # v20.x # Check npm npm --version # 10.x # Check AWS CLI aws --version # aws-cli/2.x # Check CDK cdk --version # 2.x # Check Git git --version # 2.x # Check AWS credentials aws sts get-caller-identity # Check project dependencies cd OJT_infrastructure npm list --depth=0 Troubleshooting Issue: Node.js version mismatch\n# Use nvm to switch versions nvm install 20 nvm use 20 Issue: AWS CLI not found\nRestart terminal after installation Check PATH environment variable Issue: CDK command not found\n# Reinstall CDK globally npm uninstall -g aws-cdk npm install -g aws-cdk Issue: AWS credentials invalid\n# Reconfigure AWS CLI aws configure # Enter correct credentials Next Steps Once your environment is set up, proceed to [CDK Bootstrap] to prepare your AWS account for CDK deployments.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/2-proposal/","title":"Proposal","tags":[],"description":"","content":"AWS First Cloud AI Journey – Project Plan Online Shopping Website: Furious Five Fashion (FFF) AWS \u0026amp; AI-Powered E-commerce Website Solution 1. Background and Motivation 1.1 Executive Summary The client is a small-sized business specializing in fashion products for young customers. They aim to build an online clothing e-commerce website using AWS and AI, with the ability to scale flexibly, support long-term growth, and optimize operational costs.\nThe goal of this project is to shift from traditional manual management on physical servers to a flexible, intelligent, and cost-efficient cloud-based model. AWS enables the system to scale at any time, maintain fast access speed, and allow the business to focus on product development instead of infrastructure.\nThe system is designed to support end-to-end e-commerce operations: hosting and distributing web content, managing product and order databases, supporting payments, and monitoring system performance. Everything aims toward stability, security, and long-term scalability.\nThe Furious Five implementation team will accompany the client throughout the process—advising, designing the architecture, and configuring key AWS services such as Lambda, S3, DynamoDB, CloudFront, and Route 53. Beyond building the system, they also help optimize costs, ensure security, and train the internal team to manage the infrastructure effectively.\nThis project is not just a technical plan—it marks an important step in the company’s digital transformation journey.\n1.2 Project Success Criteria To ensure the success of the Furious Five Fashion project, the following clear and measurable criteria must be met, representing both business goals and technical effectiveness:\nSystem Performance The website must maintain response times under 2 seconds for all user actions, even during peak hours.\nAvailability The system must achieve 99.9% uptime, monitored and automatically reported through services like CloudWatch.\nScalability AWS infrastructure must scale automatically when traffic increases by at least 2× without causing service disruption.\nCost Optimization Monthly operating costs must remain under 30% of the projected budget, supported by AWS cost-monitoring tools such as Cost Explorer and Trusted Advisor.\nSecurity No data leaks or unauthorized access. All customer data must be protected by AWS security standards (IAM policies, encryption, HTTPS, etc.).\nDeployment \u0026amp; Operations Infrastructure must be fully deployed within 4 weeks, with complete documentation so the internal team can manage the environment effectively.\nTraining \u0026amp; Knowledge Transfer The internal technical team must be trained to confidently maintain, monitor, and secure the system without depending entirely on external support.\n1.3 Assumptions To ensure alignment and smooth execution of the FFF project, the following assumptions have been made:\nThe team already has access to AWS accounts with required permissions and has basic knowledge of essential AWS services such as Lambda, S3, IAM, and Route 53. Stable Internet connectivity is assumed since all infrastructure runs in the cloud. The team is also aware of basic security and compliance requirements before deployment.\nThe project depends on multiple external factors: stable service availability in the selected AWS region, smooth domain routing via Route 53, and effective collaboration between development teams to ensure the web application operates properly in the cloud environment.\nThe project is part of an internship, so the budget is limited—favoring free-tier usage and low-cost service configurations. Due to limited experience and tight timelines, the chosen architecture remains simple and practical.\nPotential risks include IAM misconfigurations, accidental overspending due to unused resources, AWS regional outages, service incompatibilities, or limited expertise in troubleshooting cloud systems.\nDespite these risks, the project is built on clear expectations: this is a pilot environment, with layered monitoring, backup, and cost-management strategies in place. Every challenge is considered an opportunity to learn and grow in cloud engineering.\n2. SOLUTION ARCHITECTURE 2.1 Technical Architecture Diagram The following architecture is designed for FFF, deployed in AWS Region Singapore (ap-southeast-1). It emphasizes flexibility, security, automation, scalability, and simplicity—appropriate for an internship-level project while following AWS best practices.\nThe system follows a multi-layer design consisting of six key components:\nFrontend \u0026amp; Security Layer Users access the website through Route 53. Incoming traffic is protected with AWS WAF and optimized via CloudFront. Source code is managed and deployed through GitLab CI/CD using CloudFormation templates.\nAPI \u0026amp; Compute Layer API Gateway routes all requests to AWS Lambda, which handles application logic. Cognito manages authentication and access control.\nStorage Layer Two S3 buckets store static content (StaticData) and user uploads.\nData Layer DynamoDB stores product metadata and unstructured data. IAM ensures secure interactions between components.\nAI Layer Amazon Rekognition and Amazon Bedrock power image processing and generative AI features.\nObservability \u0026amp; Security Layer CloudWatch, SNS, and SES provide monitoring, alerting, and system notifications.\n2.2 Technical Implementation Plan Infrastructure will be managed and deployed using Infrastructure as Code (IaC) with AWS CloudFormation to ensure repeatability, stability, and ease of maintenance.\nKey AWS components—S3, Lambda, API Gateway, VPC, RDS , Cognito, and CloudWatch—will be defined entirely through CloudFormation templates stored in GitLab for version control and rollback capability.\nSensitive configurations such as IAM permissions or WAF rules require approval before deployment and follow the internal governance process with review and validation.\nAll critical system paths—from authentication to data processing—are covered by automated and manual test cases to ensure stability, security, and scalability.\nThis technical plan enables the FFF team to deploy and manage a professional cloud environment, learning real DevOps and AWS best practices.\n2.3 Project Plan The project follows Agile Scrum over 3 months, divided into 4 sprints.\nSprint Structure\nSprint Planning\nSetup AWS foundational services (S3, Route 53, IAM)\nConfigure security (WAF, CloudFront)\nIntegrate backend (Lambda, API Gateway, RDS)\nTesting, optimization, and demo preparation\nDaily Stand-up 30-minute updates to address blockers and track status.\nSprint Review Review deliverables, demo on real AWS environment, fix issues.\nRetrospective Improve DevOps workflows and automation pipeline.\nTeam Roles\nProduct Owner: Business alignment, backlog prioritization\nScrum Master: Coordination, Agile process enforcement\nDevOps/Technical Team: Backend, infrastructure, CI/CD\nMentor / AWS Partner: Architecture validation, AI testing, cost \u0026amp; security review\nCommunication Rhythm\nDaily Stand-ups (23:00)\nWeekly Sync\nEnd-of-Sprint Demo\nKnowledge Transfer After the final sprint, the technical team will deliver hands-on training on operations, monitoring (Budgets, CloudWatch), scaling, and recovery procedures.\n2.4 Security Considerations Access Management MFA for admin users; IAM roles with least privilege; auditing through CloudTrail.\nInfrastructure Security\ndedicated VPC, services are restricted using resource policies; all public endpoints use HTTPS.\nData Protection\nS3 and RDS encryption; TLS data transfer; manual periodic backups.\nDetection \u0026amp; Monitoring\nCloudTrail, Config, and CloudWatch for visibility; GuardDuty for threat detection.\nIncident Response\nClear incident workflows with log collection, analysis, and periodic simulations.\n3. PROJECT ACTIVITIES \u0026amp; DELIVERABLES 3.1 Activities \u0026amp; Deliverables Table Phase Timeline Activities Deliverables Effort(day) Infrastructure Setup Week 1 – 2 Requirements gathering, architecture design, AWS configuration (S3, CloudFront, API, Lambda, RDS, Cognito), GitLab CI/CD setup Completed AWS Architecture, Ready Infrastructure, Active CI/CD 10 Frontend Development Week 3–5 UI/UX design, FE pages (Home, Catalog, Product Detail, Cart, Checkout), API integration Completed FE (Dev), Frontend connected to API 15 Backend \u0026amp; Database Week 6–9 Lambda APIs, RDS setup, order/user/product logic, Cognito IAM setup Stable API, validated data flow, full Frontend–Backend integration 20 Testing \u0026amp; Validation Week 10–11 Functional, security, performance testing, integration testing Test Report, Validated System 5 Production Launch Week 12 Deploy to production, domain \u0026amp; SSL setup, training \u0026amp; handover Live FFF Website, Documentation Package 5 3.2 Out of Scope The following items were discussed during the requirements definition phase, but were determined to be out of scope for the FFF Web Clothing project at the current stage.\nItems out of scope include:\nMobile App development for the system (Android/iOS). Integration of real-world inventory, shipping and logistics management systems (Fast Delivery, GHN, Viettel Post, etc.). Advanced administrative functions such as multi-level authorization, automatic revenue reporting, advanced statistical charts. Integration of third-party CRM (Customer Relationship Management) or ERP (Enterprise Resource Planning). Use of AWS services with higher, more expensive automatic security features. Integration of real-world payment gateways (VNPay, Momo, ZaloPay, Stripe, PayPal, etc.) Multilingual and multi-currency 3.3\tPATH TO PRODUCTION Phase 1 – Prototype (POC)\nActivities: Build a test version of FFF Web Sales with basic interface (Home, Category, Product Details, Cart).\nConnect backend via API Gateway – Lambda – DynamoDB.\nDeploy static website on Amazon S3 + CloudFront.\nConfigure admin account and demo trial order process.\nPhase 2 – Complete system and test (UAT)\nActivities:\nAdd user functions: login/register, authentication via AWS Cognito.\nAdd trial payment feature via sandbox.\nAdd monitoring with Amazon CloudWatch and error handling log.\nPerform internal user testing (User Acceptance Test).\nPhase 3 - Official Operation Deployment (Production)\nActivities:\nMove the entire system from the test environment to Production AWS. Configure Route53 for the official domain and SSL certificate via AWS Certificate Manager. Set up external security with AWS WAF. Optimize S3 capacity and CDN structure on CloudFront. Phase 4 – Stabilization \u0026amp; optimization after deployment\nActivities:\nMonitor actual AWS costs, optimize storage and logs.\nAdjust Lambda configuration to reduce cold start time.\nPerform periodic backups and test data recovery.\nUpdate operational documentation for the administration team.\nSummary\nThe FFF Web Sales system has been successfully deployed on the AWS Serverless platform with a cost-optimized, highly secure and scalable architecture. The stages were completed on schedule, ensuring that all functions were tested, refined and operated stably. The project is now ready to expand real users and integrate more advanced e-commerce features.\n4. AWS COST ESTIMATION Estimated monthly cost:\nRoute 53 : $1.00 AWS WAF : $5.00 CloudFront: $3.90 Amplify: $10.00 S3 (StaticData) : $0.50 S3 (Uploads): $0.75 S3 (Bucket): $0.75 AWS Lambda: $0.25 API Gateway: $3.50 Amazon Bedrock: $3.00 RDS: $21.00 IAM: Free CloudWatch: $2.00 SNS: $0.10 SES: $0.20 CloudFormation: Free GitLab CI/CD : $3.00 WS Config / Setup \u0026amp; Test migration tools $5.00 (1 lần) Estimated monthly total cost: ~ $50.00 – $55.00 USD KEY ASSUMPTIONS\nRegion: ap-southeast-1 (Singapore). User access: 100–200/month. The system is always running 24/7 but low load. Mostly API via Lambda. Small data (\u0026lt;30GB total). CI/CD 1–2 deployments per week. Free-tier is valid for the first 12 months. AI is used for demo purposes, not large-scale inference.\nSUGGESTED COST OPTIMISATION\nEnable S3 Intelligent-Tiering to automatically move less frequently accessed data. Limit CloudWatch Logs to 14–30 days. Use AWS Budgets to alert if it exceeds $40/month. If deploying long-term → consider Savings Plan for Lambda (30–40% reduction).\n5. Team Partner Executive Sponsor Name: Nguyen Gia Hung Title: FCJ Vietnam Training Program Director Description: Responsible for overall oversight of the FCJ internship program\nEmail/contact information: hunggia@amazon.com|\nProject Stakeholders Name: Van Hoang Kha Title: Support Teams Description: Responsible for overall supervision of the FCJ internship program as the Executive Support person.\nEmail/Contact information: Khab9thd@gmail.com\nPartner Project Team (Furious Five Internship Team)\nName: Duong Minh Duc Title: Project Team Leader\nDescription: Manage progress, coordinate work between the team and mentor, Manage AWS infrastructure deployment (S3, Lambda, IAM)\nEmail/Contact information: ducdmse182938@fpt.edu.vn\nName: Quach Nguyen Chi Hung\nTitle: Member\nDescription: In charge of UI/UX and user interface\nEmail/Contact information: bacon3632@gmail.com\nName: Nguyen Tan Xuan\nTitle: Member\nDescription: Responsible for Backend and server logic processing\nEmail/Contact information: xuanntse184074@fpt.edu.vn\nName: Nguyen Hai Dang\nTitle: Member\nDescription: Manage AWS infrastructure deployment (S3, Lambda, IAM) and AI chat bot integration\nEmail/Contact information: dangnhse184292@fpt.edu.vn\nName: Pham Le Huy Hoang\nTitle: Member\nDescription: Testing, quality assurance and GitLab CI/CD integration, and AI chat bot integration\nEmail/Contact information: hoangplhse182670@fpt.edu.vn\nProject Escalation Contacts Name: Duong Minh Duc\nTitle: Project Team Leader\nDescription: Represent the internship team to contact the mentor and sponsor directly\nEmail/Contact information: ducdmse182938@fpt.edu.vn\n6. RESOURCES \u0026amp; COST ESTIMATES Resources Role Responsibilities Fee (USD)/Hour Solution Architect(1) Design overall solution, ensure technical feasibility, select appropriate AWS service 35 Cloud Engineer(2) Deploy AWS infrastructure, configure services (S3, IAM\u0026hellip;), test and optimize system 20 Project Manager (1) Monitor progress, coordinate team, manage scope and risk for the project. 15 Support / Documentation (1) Prepare communication documents, user manuals and summary reports. 10 Estimate costs by project phase Project Phase Solution Architect (hrs) 2 Engineers (hrs) Project Manager (hrs) Project Management/Suppor(hrs) Total Hours Survey \u0026amp; Solution Design 53 40 13 13 119 Implementation \u0026amp; Testing 67 160 21 19 267 Handover \u0026amp; Support 27 53 21 19 120 Total Hours 147 253 55 51 506 Total Amount $5145 $5060 $825 $510 $11540 Cost Contribution Allocation Party Contribution (USD) % Contribution Customer 4616 40% Partner (Furious Five) 2308 20% AWS 4616 40% 7.\tACCEPTANCE Since this project is currently at the presentation stage and has not yet been formally evaluated by a customer, the following acceptance process is proposed for future delivery phases:\n7.1 Acceptance Criteria (Proposed) A deliverable will be considered acceptable when it meets the following criteria:\nFunctional features work as specified (authentication, recipe management, social features, AI functions). All APIs respond correctly and integrate with AWS services (Lambda, API Gateway, RDS, S3). Security requirements are met (JWT verification, HTTPS, access control, data encryption). UI works as expected on supported devices. No critical errors appear during test execution. 7.2 ACCEPTANCE PROCESS Review period: 8 business days for evaluation and testing. If accepted → Deliverable is signed off. If issues are found → A rejection notice will be issued with feedback. Fixes will be applied and a revised version will be resubmitted for review. If no response is received by the end of the review period → Deliverable is deemed accepted. After completing each milestone, the team submits the deliverables and documentation. !!Download Full Proposal (DOCX)\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Learning modules and participating in AWS events Gaining more understanding of AWS features. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Deep dive into AWS - Role of IAM with EC2 09/15/2025 09/15/2025 3 - Continue working on module 2 and gain more insights into AWS financial management + Develop with Cloud9 on AWS + Static website hosting with Amazon S3 +Account got locked 06/16/2025 09/16/2025 4 - Essential database with Amazon RDS service \u0026amp;emsp + Recreate AWS account \u0026amp;emsp + Create DB subnet group\n+ Set up basic parameter group 09/17/2025 09/17/2025 5 - Attend Cloud Day Vietnam 2025: AI Edition + Join track 2 Migration \u0026amp; Modernization 09/18/2025 09/18/2025 6 - Continue module 2 + Simplified Computing with Amazon Lightsail + Container Deployment with Amazon Lightsail Containers 09/19/2025 09/19/2025 Week 2 Achievements: 1 Role of IAM with EC2\nCreate IAM Role Attach IAM Role to EC2 Instance 2 Development with Cloud9 on AWS\nCreate Cloud9 environment Work inside IDE Clean up resources 3 Static website with Amazon S3\nCreate S3 bucket Integrate domain name and HTTPS Optimize and monitor the system 4 Essential database with Amazon RDS service\nSet up VPC and Subnet Group Create RDS Database Instance 5 Simplified Computing with Amazon Lightsail\n6 Container Deployment with Amazon Lightsail Containers\nThese two parts are mainly about creating an environment for the website and consolidating cost-optimization solutions. Lessons learned: Assign permissions for applications running on EC2 instances to access other AWS services. Build a flexible development environment to reduce configuration burden. Create additional storage and distribution for static websites, improving durability, scalability, and reducing costs. ain understanding of AWS security. Deploy and manage containers without needing to operate a load balancer. Pay close attention to account management to avoid account lockout. "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Lessons Learned: AWS Cloud Mastery Series #1 — AI/ML/GenAI on AWS 1. Event Purpose Provide an overview of AI/ML in Vietnam.âfas\nPresent AWS\u0026rsquo;s core AI/ML services, especially Amazon SageMaker.\nClarify Generative AI applications through Amazon Bedrock and techniques such as RAG, Prompt Engineering.\n2. Main Content Morning: Overview of AWS AI/ML Services Introduce AI/ML context and workshop objectives.\nPresent Amazon SageMaker and the full ML process: Data Prep → Labeling → Training → Tuning → Deployment.\nMLOps model and integration into the development process.\nLive demo of SageMaker Studio.\nAfternoon: Generative AI with Amazon Bedrock Introduction to Foundation Models and selection criteria (Claude, Llama, Titan\u0026hellip;). Advanced Prompt Engineering techniques: Chain-of-Thought (CoT), Few-shot learning. Explain RAG architecture and integration with Knowledge Base. Bedrock Agents and how to build multi-step workflows. Guardrails and content control mechanism. Demo of building GenAI chatbot on Bedrock. 3. Knowledge extracted Understand SageMaker as a full ML platform serving the entire model lifecycle. Understand the role of Bedrock, the characteristics of each Foundation Model and core GenAI techniques. Be able to apply RAG and Bedrock Agents to improve chatbot in Travel-Guided project. Understand the actual deployment process through demos. 4. Hands-on experience Demos demonstrate Bedrock\u0026rsquo;s fast prototyping speed and strong integration capabilities. Opportunities to interact directly with AWS experts and the AI/ML community in Vietnam. "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/5.03-cdk-bootstrap/","title":"CDK Bootstrap","tags":[],"description":"","content":"Overview AWS CDK Bootstrap prepares your AWS account for deploying CDK applications by creating essential infrastructure resources. This is a one-time setup process per AWS account/region combination that establishes the foundation for all CDK deployments.\nWhat CDK Bootstrap Creates The bootstrap process provisions the following AWS resources in your account:\n1. S3 Bucket (CDK Assets Bucket)\nStores Lambda function deployment packages Stores CloudFormation templates Stores file assets referenced by your CDK stacks Naming pattern: cdk-hnb659fds-assets-{ACCOUNT-ID}-{REGION} Versioning enabled for rollback support 2. CloudFormation Stack (CDKToolkit)\nMain infrastructure stack containing all bootstrap resources Stack name: CDKToolkit Manages lifecycle of bootstrap resources 3. IAM Roles\ncdk-hnb659fds-cfn-exec-role: CloudFormation execution role for deploying stacks cdk-hnb659fds-deploy-role: Role used by CDK CLI during deployment cdk-hnb659fds-file-publishing-role: Role for uploading assets to S3 cdk-hnb659fds-lookup-role: Role for reading environment context 4. SSM Parameters\n/cdk-bootstrap/hnb659fds/version: Stores bootstrap version number Used for compatibility checking Infrastructure Stacks Overview After bootstrapping, our OJT E-commerce project will deploy multiple CDK stacks defined in OJT_infrastructure/lib/stacks:\nStack File Description NetworkStack network-stack.ts VPC, Subnets, NAT Gateway, Security Groups StorageStack storage-stack.ts S3 Buckets (Images, Logs) AuthStack auth-stack.ts Cognito User Pool \u0026amp; Identity Pool DatabaseStack database-stack.ts RDS SQL Server + Secrets Manager ApiStack api-stack.ts API Gateway + 11 Lambda Modules FrontendStack frontend-stack.ts S3 + CloudFront (OAC) MonitoringStack monitoring-stack.ts CloudWatch Dashboard \u0026amp; Alarms These stacks depend on the bootstrap infrastructure to deploy successfully.\nLab Instructions: Bootstrap Your AWS Account Prerequisites Before beginning this lab, ensure you have:\nAWS CLI installed and configured (see section 5.02) AWS CDK CLI installed (see section 5.02) Valid AWS credentials configured IAM user with AdministratorAccess permissions or equivalent Terminal/PowerShell access to the project directory Step 1: Navigate to Infrastructure Directory cd OJT_infrastructure Step 2: Get Your AWS Account ID aws sts get-caller-identity --query Account --output text ```bash # Bootstrap CDK for ap-southeast-1 region cdk bootstrap aws://YOUR_ACCOUNT_ID/ap-southeast-1 # Example: cdk bootstrap aws://123456789012/ap-southeast-1 Expected Output:\nBootstrapping environment aws://123456789012/ap-southeast-1... Environment aws://123456789012/ap-southeast-1 bootstrapped. ![CDK Bootstrap Success] Screenshot: Terminal showing CDK bootstrap completed successfully\nStep 4: Verify Bootstrap via CLI # Check bootstrap version aws ssm get-parameter \\ --name /cdk-bootstrap/hnb659fds/version \\ --region ap-southeast-1 \\ --query Parameter.Value \\ --output text # Expected output: A version number (e.g., 19) ![Bootstrap Verification CLI] Screenshot: Terminal showing bootstrap version verification\nStep 5: Verify on AWS Console Confirm resources in the AWS Management Console.\n5.1. Verify CloudFormation Stack\nOpen [CloudFormation Console] Look for stack named CDKToolkit Status should be CREATE_COMPLETE Click on Resources tab to view created resources ![CloudFormation CDKToolkit Stack] Screenshot: CloudFormation console showing CDKToolkit stack\n5.2. Verify S3 Bucket\nOpen S3 Console Find bucket: cdk-hnb659fds-assets-{ACCOUNT-ID}-ap-southeast-1 Verify bucket properties: Versioning: Enabled ![S3 Bucket Console] Screenshot: S3 console showing CDK assets bucket\n5.3. Verify IAM Roles\nOpen IAM Roles Console Search for: cdk-hnb659fds Verify the following roles exist: cdk-hnb659fds-cfn-exec-role-{ACCOUNT-ID}-ap-southeast-1 cdk-hnb659fds-deploy-role-{ACCOUNT-ID}-ap-southeast-1 cdk-hnb659fds-file-publishing-role-{ACCOUNT-ID}-ap-southeast-1 cdk-hnb659fds-lookup-role-{ACCOUNT-ID}-ap-southeast-1 ![IAM Roles Console] Screenshot: IAM console showing CDK bootstrap roles\nUnderstanding Bootstrap Resources S3 Bucket Details The CDK assets bucket serves as a central repository for all deployment artifacts:\nPurpose: Stores CloudFormation templates, Lambda deployment packages, and static assets Lifecycle: Persists across deployments, enabling rollback capabilities Security: Encrypted at rest, bucket policies restrict access to authorized roles Naming: Deterministic naming based on account ID and region IAM Roles Details 1. CloudFormation Execution Role (cfn-exec-role)\nUsed by CloudFormation to create/update/delete stack resources Has broad permissions to manage AWS resources Trust relationship with CloudFormation service 2. Deploy Role (deploy-role)\nUsed by CDK CLI during cdk deploy operations Can assume the CloudFormation execution role Has permissions to upload assets and initiate deployments 3. File Publishing Role (file-publishing-role)\nUploads Lambda packages and assets to S3 Has S3 write permissions to the assets bucket 4. Lookup Role (lookup-role)\nReads environment context (VPCs, subnets, etc.) Read-only permissions for resource lookups Used during synthesis for context queries Cost Analysis Bootstrap Resources Cost One-time Setup:\nCloudFormation stack creation: Free IAM roles creation: Free SSM parameters: Free Ongoing Monthly Costs:\nResource Usage Cost (Estimated) S3 Storage \u0026lt; 1 GB (typical) $0.023/GB = ~$0.02/month S3 Requests Minimal (GET/PUT) ~$0.01/month IAM Roles No charge $0.00 Total Estimated Cost: ~$0.03/month (negligible)\nNote: For serverless applications, costs remain minimal as we only store Lambda deployment packages in S3.\nTroubleshooting Issue: Bootstrap fails with permission error\n# Ensure your IAM user has AdministratorAccess aws iam list-attached-user-policies --user-name YOUR_USERNAME Issue: Region mismatch\n# Verify your default region aws configure get region # Bootstrap specific region cdk bootstrap aws://ACCOUNT_ID/ap-southeast-1 Issue: CDK version mismatch\n# Update CDK CLI npm update -g aws-cdk # Verify version cdk --version Lab Completion Checklist Ensure you have completed all steps:\nStep 1: Navigate to OJT_infrastructure directory Step 2: Retrieved your AWS account ID Step 3: Executed CDK bootstrap command Step 4: Verified bootstrap version via CLI Step 5.1: Verified CDKToolkit CloudFormation stack Step 5.2: Verified CDK assets S3 bucket Step 5.3: Verified IAM roles created Summary In this lab, you successfully:\nExecuted CDK bootstrap command for your AWS account (ap-southeast-1) Created CDKToolkit CloudFormation stack Provisioned CDK assets S3 bucket for storing Lambda packages Created necessary IAM roles for CDK deployments Verified all resources via CLI and AWS Console Your AWS account is now ready to deploy serverless CDK applications, including the infrastructure stacks for the OJT E-commerce project.\nNext Steps Proceed to [Deploy Core Infrastructure] to deploy VPC, Database, Storage, and Auth stacks.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Continue learning and exploring more AWS functionalities. Module 3 Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Scaling Applications with EC2 Auto Scaling - Monitoring with Amazon CloudWatch 09/22/2025 09/22/2025 3 - Hybrid DNS Management with Amazon Route 53 - Command Line Operations with AWS CLI 09/23/2025 09/23/2025 4 - NoSQL Database Essentials with Amazon DynamoDB - In-Memory Caching with Amazon ElastiCache 09/24/2025 09/24/2025 5 - Networking on AWS Workshop - Write Proposal 09/25/2025 09/25/2025 6 - Content Delivery with Amazon CloudFront - Write Proposal 09/26/2025 09/26/2025 Achievements in Week 3: Understanding application deployment architecture on AWS with scalability using EC2 Auto Scaling:\nCreate Launch Template Configure Load Balancer (Target Group + Load Balancer) Create Auto Scaling Group Experiment with scaling methods: manual, scheduled, dynamic/predictive Read metrics/data from predictive scaling Cleanup resources afterward Capabilities achieved:\nDeploy a web application with scalable architecture. From an application running on a single server, you can move to a cluster architecture with load balancing and auto scaling. Basic EC2 practice:\nMonitoring with Amazon CloudWatch Hybrid DNS Management with Amazon Route 53 Command Line Operations with AWS CLI EC2 Instance initialization and management:\nCreate, configure, and launch EC2 Connect to the instance via SSH Manage lifecycle (Start/Stop/Terminate) Networking \u0026amp; Security:\nCreate and edit Security Groups to control access Use Elastic IP for assigning static IP to EC2 Application Deployment:\nInstall basic software on EC2 Deploy a simple web application Skills gained:\nMastering virtual server administration on AWS Understanding connection and security for application infrastructure Storage \u0026amp; Access Management:\nNoSQL Database Essentials with Amazon DynamoDB In-Memory Caching with Amazon ElastiCache Networking on AWS Workshop Amazon S3 (Simple Storage Service):\nCreate and manage buckets Upload/Download data Configure access permissions (public/private) Manage Versioning to track file history IAM (Identity and Access Management):\nCreate Users, Groups, Roles Assign Policies following the “least privilege” principle Manage Access Keys and Secret Keys securely CloudWatch:\nMonitor system metrics Record logs for EC2 and other services Skills gained:\nBuild security and access control foundation in AWS\nMonitor and optimize system operations\nContent Delivery with CloudFront + S3\nAmazon CloudFront:\nCDN service that speeds up content delivery using caching at edge locations\nS3 + CloudFront integration:\nS3 bucket as origin storing static content (HTML, CSS, JS, images)\nCloudFront distributes and caches content, reducing latency for end-users\nPractice:\nCreate an S3 bucket and upload content Create CloudFront distribution pointing to S3 origin Configure cache policy, TTL, and access permissions Test website delivery via CloudFront Delete resources after completion to avoid costs Skills gained:\nBuild a high-performance static website using S3 + CloudFront Manage caching and secure content delivery Takeaways after the workshop series: Foundational knowledge: Understanding AWS core services Administration skills: Practice managing resources through Console and CLI Application deployment: Create EC2, configure networking, distribute content with S3 + CloudFront Security \u0026amp; monitoring: Manage permissions with IAM, monitor systems with CloudWatch Practical application ability: Capable of deploying a basic web system on AWS with performance, security, scalability, and cost optimization. "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Lessons Learned: AWS Cloud Mastery Series #2 — DevOps on AWS 1. Event Objectives Enhance understanding of DevOps mindset and culture. Clarify AWS CI/CD services: CodeCommit, CodeBuild, CodeDeploy, CodePipeline. Gain knowledge of Infrastructure as Code with CloudFormation and AWS CDK. Learn about Container services (ECS, EKS, App Runner) and observability systems (CloudWatch, X-Ray). 2. Main Contents Morning: CI/CD Pipeline \u0026amp; Infrastructure as Code DevOps Mindset and DORA metrics (Deployment Frequency, MTTR…).\nCI/CD System:\nSource: CodeCommit and Git strategy.\nBuild/Test: CodeBuild.\nDeployment: CodeDeploy with Blue/Green, Canary, Rolling.\nPipeline: automation with CodePipeline.\nDemo of a complete CI/CD pipeline.\nInfrastructure as Code:\nCloudFormation: templates, stacks, drift detection.\nAWS CDK: constructs, reusable patterns, multi-language.\nDemo and discussion of appropriate IaC options.\nAfternoon: Container \u0026amp; Observability Container Services: Docker: basic containerization knowledge. Amazon ECR: storage, scanning and lifecycle image management. Amazon ECS/EKS: deployment, scaling, orchestration. App Runner: PaaS for containers. Monitoring \u0026amp; Observability: CloudWatch: metrics, logs, alarms, dashboards. AWS X-Ray: distributed tracing for microservices. Best Practices: Feature flags, A/B testing. Incident management and postmortems. Demo and case study: evaluate deployment strategy for microservices. 3. Knowledge learned Understand DevOps thinking and the meaning of DORA metrics. Understand how to coordinate between Code* services to build a complete CI/CD. Have a solid foundation in IaC (CloudFormation, CDK) to optimize multi-stack architecture. Clearly see the importance of Monitoring/Tracing through CloudWatch and X-Ray. Understand container architecture orientation with ECS/EKS for large-scale systems. Practical CI/CD \u0026amp; IaC demo, immediately applicable to projects. 4. Experience the event Clear, practical content. Demo and case study support easy visualization of the deployment process. Opportunity to connect directly with experts and the DevOps community in Vietnam. "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"This section will list and introduce the blogs you have translated. For example:\nBlog 1 -Enabling customers to deliver production-ready AI agents at scale Nomalab leverages AWS services and generative AI to automate ad break detection in media workflows. Using Media2Cloud, Amazon Rekognition, Amazon Transcribe, Amazon Bedrock, and Amazon OpenSearch Service, the platform detects visual and audio cues, analyzes conversation flow, and generates contextual metadata for precise, frame-accurate ad placement. This automation achieves near-human accuracy, accelerates content processing from hours to entire libraries, scales cost-effectively, and enables media companies to optimize operations while maintaining high-quality viewer experiences.\nBlog 2 - Optimize Multimodal Search Using the TwelveLabs Embed API and Amazon OpenSearch Service This blog demonstrates how AWS enables organizations to implement multimodal video search and analysis at scale using a vector-based architecture. You will learn why combining TwelveLabs Embed API with Amazon OpenSearch Service is critical for extracting insights from video content, how this integration supports text-, image-, and audio-to-video search, and how AWS services such as OpenSearch, Secrets Manager, and supporting SDKs form a secure, scalable, and modular solution. The article also covers architecture design, indexing and search workflows, and real-world use cases showing how enterprises can efficiently manage, analyze, and retrieve information from large video libraries.\nBlog 3 - Optimizing Network Footprint in Serverless Applications WS helps developers optimize network footprint in serverless applications using data compression techniques. You will learn why compression is critical for transferring large payloads in services like AWS Lambda, API Gateway, SQS, and EventBridge, how it reduces latency and costs, and how AWS components such as Lambda, API Gateway, and S3 form a scalable and modular solution. The article also covers architecture patterns for handling large payloads, compression workflows, sample implementation in Lambda and API Gateway, and testing results demonstrating significant network footprint reduction while balancing compute overhead.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/5.04-configure-stacks/","title":"Configure Infrastructure Stacks","tags":[],"description":"","content":"Configure Infrastructure Stacks OJT E-commerce Project Overview Introduction OJT E-commerce is a serverless e-commerce platform built entirely on AWS Cloud. The project uses a serverless architecture with Lambda functions replacing traditional Spring Boot backend, leveraging AWS managed services to ensure scalability, security, and cost optimization.\nSystem Architecture The project is designed with a 7-Stack Architecture featuring clear layers:\n┌─────────────────────────────────────────────────────────────┐ │ OJT E-commerce Platform │ ├─────────────────────────────────────────────────────────────┤ │ Layer 1: Network (Foundation) │ │ └─ Network Stack: VPC, Subnets, NAT Gateway, Security Groups│ ├─────────────────────────────────────────────────────────────┤ │ Layer 2: Data \u0026amp; Storage │ │ ├─ Storage Stack: S3 Buckets (Images, Logs) │ │ └─ Database Stack: RDS SQL Server, Secrets Manager │ ├─────────────────────────────────────────────────────────────┤ │ Layer 3: Authentication │ │ └─ Auth Stack: Cognito User Pool, Identity Pool │ ├─────────────────────────────────────────────────────────────┤ │ Layer 4: Application \u0026amp; Business Logic │ │ └─ API Stack: API Gateway, 11 Lambda Modules │ ├─────────────────────────────────────────────────────────────┤ │ Layer 5: Content Delivery │ │ └─ Frontend Stack: S3 Static Hosting, CloudFront CDN │ ├─────────────────────────────────────────────────────────────┤ │ Layer 6: Monitoring \u0026amp; Observability │ │ └─ Monitoring Stack: CloudWatch Dashboard, Alarms │ └─────────────────────────────────────────────────────────────┘ Technologies Used Infrastructure as Code AWS CDK (TypeScript): Infrastructure management with code CloudFormation: Underlying template engine for CDK Git: Version control for infrastructure code Backend Services API Gateway REST API: RESTful API endpoint Lambda Functions: Serverless compute for business logic RDS SQL Server: Relational database S3: Object storage for product images and frontend Secrets Manager: Secure credential storage Security \u0026amp; Authentication Cognito User Pool: User authentication \u0026amp; management JWT Authentication: Custom JWT-based auth in Lambda VPC: Network isolation with public/private/isolated subnets Security Groups: Firewall rules for resources IAM Roles \u0026amp; Policies: Fine-grained access control Content Delivery \u0026amp; Networking CloudFront: CDN with Origin Access Control (OAC) NAT Gateway: Internet access for private subnets VPC Endpoints: Private connectivity to AWS services Monitoring \u0026amp; Operations CloudWatch Logs: Centralized logging for Lambda functions CloudWatch Metrics: Performance metrics tracking CloudWatch Dashboard: Visualization of metrics CloudWatch Alarms: Real-time monitoring alerts Project Directory Structure OJT/ ├── OJT_infrastructure/ # AWS CDK Infrastructure │ ├── bin/ │ │ └── infrastructure.ts # CDK app entry point │ ├── lib/ │ │ └── stacks/ # Stack definitions │ │ ├── network-stack.ts # VPC, Subnets, NAT Gateway │ │ ├── storage-stack.ts # S3 Buckets │ │ ├── auth-stack.ts # Cognito User Pool │ │ ├── database-stack.ts # RDS SQL Server │ │ ├── api-stack.ts # API Gateway + Lambda │ │ ├── frontend-stack.ts # S3 + CloudFront │ │ └── monitoring-stack.ts # CloudWatch │ ├── .env.example # Environment template │ ├── package.json # Node.js dependencies │ └── tsconfig.json # TypeScript configuration │ ├── OJT_lambda/ # Lambda Functions (63 APIs) │ ├── auth/ # Authentication (4 functions) │ ├── products/ # Products (12 functions) │ ├── product-details/ # Product Details (7 functions) │ ├── cart/ # Cart (6 functions) │ ├── orders/ # Orders (9 functions) │ ├── categories/ # Categories (6 functions) │ ├── brands/ # Brands (5 functions) │ ├── banners/ # Banners (7 functions) │ ├── ratings/ # Ratings (3 functions) │ ├── users/ # Users (3 functions) │ ├── images/ # Images (1 function) │ └── shared/ # Shared utilities │ ├── OJT_frontendDev/ # Frontend (React + Vite) │ ├── src/ # Source code │ └── public/ # Static assets │ └── database/ # Database Scripts ├── schema/ # SQL schema files ├── migrations/ # Migration scripts └── seeds/ # Sample data Stack Architecture Overview 1. Network Stack (Deploy Order: 1) Purpose: Create VPC and network infrastructure\nMain resources:\nVPC: 10.0.0.0/16 CIDR block Public Subnets: 2 AZs - Internet-facing resources Private Subnets: 2 AZs - Lambda functions, internal services Isolated Subnets: 2 AZs - RDS database (no internet) NAT Gateway: 1 instance (cost optimized) Internet Gateway: VPC internet access Security Groups: Lambda SG, RDS SG VPC Endpoints: S3, Secrets Manager Estimated cost: ~$23/month (NAT Gateway)\n2. Storage Stack (Deploy Order: 2) Purpose: Create S3 buckets for images and logs\nMain resources:\nImages Bucket: Product images storage Versioning enabled Lifecycle rules for cost optimization Logs Bucket: CloudFront access logs Auto-delete after 90 days Estimated cost: ~$1-3/month\n3. Auth Stack (Deploy Order: 2) Purpose: User authentication with Cognito (Optional)\nMain resources:\nCognito User Pool: User registration and authentication Email verification required Password policy: 8+ chars, mixed case, numbers, symbols Cognito User Pool Client: Frontend authentication Cognito Identity Pool: AWS credentials for authenticated users Estimated cost: $0/month (Free tier: 50,000 MAU)\nNote: This stack is optional. The project also supports custom JWT authentication in Lambda.\n4. Database Stack (Deploy Order: 2) Purpose: SQL Server database with Secrets Manager\nMain resources:\nRDS SQL Server Express 2019: Instance: db.t3.micro (cost optimized) Storage: 20 GB gp3 SSD Multi-AZ: Disabled (dev/staging) Backup: 1 day retention Secrets Manager: Database credentials Auto-generated strong password Optional rotation Estimated cost: ~$15/month (optimized from $54)\n5. API Stack (Deploy Order: 3) Purpose: REST API with API Gateway and Lambda functions\nMain resources:\nAPI Gateway REST API: 63 endpoints across 11 modules CORS enabled CloudWatch logging Lambda Functions (11 modules): Auth, Products, ProductDetails, Cart, Orders Categories, Brands, Banners, Ratings, Users, Images Runtime: Node.js 20.x Memory: 128-512 MB (optimized) VPC: Private subnets Estimated cost: ~$2-5/month\n6. Frontend Stack (Deploy Order: 4) Purpose: Static website hosting with CDN\nMain resources:\nS3 Bucket: React build files CloudFront Distribution: Origin Access Control (OAC) HTTPS only Gzip compression Estimated cost: ~$1-2/month\n7. Monitoring Stack (Deploy Order: 5) Purpose: Monitoring, logging, and alerting\nMain resources:\nCloudWatch Dashboard: System metrics visualization CloudWatch Alarms: API Gateway 5xx errors Lambda errors RDS CPU utilization CloudWatch Log Groups: Lambda function logs Estimated cost: ~$1-2/month\nStack Dependencies Flow Network Stack (VPC, Subnets, NAT Gateway) ↓ ┌─────────────────────────────────────┐ │ Storage Stack Auth Stack │ │ (S3 Buckets) (Cognito) │ │ │ │ Database Stack │ │ (RDS SQL Server) │ └─────────────────────────────────────┘ ↓ API Stack (API Gateway + Lambda) ↓ Frontend Stack (S3 + CloudFront) ↓ Monitoring Stack (CloudWatch) Total Estimated Cost Development Environment:\nService Cost/month Notes NAT Gateway $23 1 instance RDS SQL Server $15 t3.micro Lambda $2 11 modules, 128MB S3 Storage $1.25 Images + Frontend CloudFront $1.50 CDN distribution CloudWatch $1.50 Dashboard + Logs Cognito $0 Free tier (50K MAU) API Gateway $0-3 Free tier (1M requests) TOTAL ~$44/month 60% reduction from $111 Configuration Guide Step 1: Navigate to Infrastructure Directory cd OJT_infrastructure Step 2: Install Dependencies npm install Step 3: Configure Environment Variables 1. Copy environment template\ncopy .env.example .env 2. Edit .env file with your values\n# AWS Configuration AWS_ACCOUNT_ID=123456789012 AWS_REGION=ap-southeast-1 # Database Configuration DB_NAME=demoaws DB_USERNAME=admin DB_PASSWORD=YourSecurePassword123! # Application Configuration APP_NAME=OJT-Ecommerce ENVIRONMENT=dev # JWT Secret JWT_SECRET=your-super-secret-jwt-key-change-this-in-production 3. Verify AWS Account ID\naws sts get-caller-identity Output:\n{ \u0026#34;UserId\u0026#34;: \u0026#34;AIDAXXXXXXXXXXXXXXXXX\u0026#34;, \u0026#34;Account\u0026#34;: \u0026#34;123456789012\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::123456789012:user/your-username\u0026#34; } Step 4: Validate Configuration 1. Compile TypeScript\nnpm run build 2. List all CDK stacks\nnpx cdk list Expected output:\nOJT-NetworkStack OJT-StorageStack OJT-AuthStack OJT-DatabaseStack OJT-ApiStack OJT-FrontendStack OJT-MonitoringStack 3. Synthesize CloudFormation templates\nnpx cdk synth The cdk.out/ folder is created with CloudFormation templates.\nStep 5: Review Stack Code (Optional) Network Stack (lib/stacks/network-stack.ts):\nVPC with 10.0.0.0/16 CIDR Public, Private, Isolated subnets 1 NAT Gateway (cost optimized) Security Groups for Lambda and RDS Database Stack (lib/stacks/database-stack.ts):\nRDS SQL Server Express 2019 db.t3.micro instance (cost optimized) Secrets Manager for credentials 1-day backup retention API Stack (lib/stacks/api-stack.ts):\nAPI Gateway REST API 11 Lambda modules with placeholder code VPC integration for database access Configuration Checklist Before deploying, verify the following:\nEnvironment Configuration\nAWS Account ID verified and updated in .env Region set to ap-southeast-1 Database credentials configured JWT secret configured Dependencies\nNode.js 20.x installed AWS CLI configured with credentials AWS CDK CLI installed globally npm dependencies installed (npm install) Validation\nTypeScript compilation successful (npm run build) CDK list shows all 7 stacks CDK synth generates CloudFormation templates Preparation\nCDK bootstrap completed AWS account has AdministratorAccess permissions Next Steps After completing configuration and validation, continue to:\nDeploy all stacks to AWS In the next step, you will:\nDeploy Network Stack (VPC, Subnets, NAT Gateway) Deploy Storage Stack (S3 Buckets) Deploy Auth Stack (Cognito - optional) Deploy Database Stack (RDS SQL Server) Deploy API Stack (API Gateway + Lambda) Deploy Frontend Stack (S3 + CloudFront) Deploy Monitoring Stack (CloudWatch) "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Continue to explore and learn about AWS services Researching and proceeding with the E-commerce Web Project. Participated in the AI-DLC (AI-Driven Development Lifecycle) event. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Edge Computing with CloudFront and Lambda@Edge - Windows Workloads on AWS 29/09/2025 29/09/2025 3 - Directory Services with AWS Managed Microsoft AD - Building Highly Available Web Applications - Project development 30/09/2025 30/09/2025 4 - VM Migration with AWS VM Import/Export - Project development 01/10/2025 01/10/2025 5 - Database Migration with AWS Database Migration Service (DMS) and Schema Conversion Tool (SCT) - Project development 02/10/2025 02/10/2025 6 - Attend AI-DLC event - Summarize Week 2 progress for E-commerce Website Project 03/10/2025 03/10/2025 Week 4 Achievements: Understanding AWS services for system deployment and migration Gained a solid understanding of the VM Import/Export process between on-premise and AWS environments.\nLearned how to use AWS Directory Service to deploy and manage Active Directory in AWS.\nDeployed WordPress on AWS Cloud architecture, including EC2, RDS, Auto Scaling, Load Balancer, and CloudFront.\nUnderstood the database schema conversion and data migration process using AWS DMS \u0026amp; SCT.\nBecame familiar with Amazon WorkSpaces – a virtual desktop service for enterprise environments.\nCapabilities Acquired Able to deploy and scale a web application from a single server to a multi-tier architecture with Auto Scaling and Load Balancing.\nCombine multiple AWS services to build a complete, scalable system (EC2 + RDS + S3 + CloudFront).\nPerform database migration between different environments.\nCreate and manage virtual workspace environments (WorkSpaces) for internal users.\nPractical Hands-on Activities a. VM Import/Export:\nImported virtual machines from on-premise environments to AWS (via S3 → AMI → EC2). Exported virtual machines from AWS back to on-premise. Managed access permissions and ACLs for S3 buckets. Cleaned up unused resources after the practice. b. AWS Directory Service:\nCreated a Managed Microsoft AD. Joined Windows EC2 instances to the domain. Managed users, groups, and policies via Active Directory. Configured DNS and internal network settings. c. WordPress Deployment on AWS Cloud:\nCreated VPC and subnets (public/private). Configured Security Groups, Load Balancer, Auto Scaling Group. Deployed WordPress on EC2 and connected it to RDS. Integrated CloudFront CDN to improve performance. Performed database backup and restoration. d. Database Migration (DMS \u0026amp; SCT):\nConverted database schema using AWS Schema Conversion Tool (SCT). Migrated data using AWS Database Migration Service (DMS). Configured replication instances, endpoints, and migration tasks. Monitored migration progress using CloudWatch Metrics. e. Amazon WorkSpaces:\nCreated and configured virtual desktop environments. Managed users and access permissions. Tested connectivity and performance of the workspace sessions. Skills Gained Practiced a real-world migration process from on-premise to AWS Cloud.\nMastered deployment of scalable web applications on AWS.\nDeepened understanding of Load Balancing, Auto Scaling, Directory Services, Migration, and WorkSpaces.\nLearned how to clean up and optimize AWS resources to reduce unnecessary costs.\nAcquired the ability to design, deploy, and manage multi-service AWS systems efficiently.\nFinally, this week was quite intense — special thanks to Mr. Thịnh Nguyễn for his support and guidance.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Lessons Learned: AWS Cloud Mastery Series #3 — AWS Well-Architected Security Pillar 1. Event Purpose Introduce the role of Security Pillar in AWS Well-Architected Framework. Present 5 pillars of security: IAM, Detection, Infrastructure Protection, Data Protection, Incident Response. Provide best practices and real-world scenarios to protect applications in the Cloud environment. 2. Main Content Pillar 1 — Identity \u0026amp; Access Management (IAM) Principles: Least Privilege, Zero Trust, Defense in Depth. Modern IAM: Avoid long-term credentials, prioritize IAM Roles and managed policies. IAM Identity Center: SSO, Permission Sets, centralized access management. Multi-account security: Service Control Policies and Permission Boundaries. Mini demo: Test IAM policy and simulate access behavior. Pillar 2 — Detection Continuous monitoring with CloudTrail (org-level), GuardDuty, Security Hub. Multi-tier logging: VPC Flow Logs, ALB logs, S3 access logs. Automated alerts via Amazon EventBridge. Pillar 3 — Infrastructure Protection Network security: network separation (public/private VPC). Defense mechanisms: Security Groups vs NACLs, AWS WAF, Shield, Network Firewall. Workload security: EC2, ECS/EKS at basic level. Pillar 4 — Data Protection At-rest and in-transit data encryption (S3, EBS, RDS, DynamoDB). KMS for key management; Secrets Manager and Parameter Store for secrets management. Data classification and access guardrails setup. Pillar 5 — Incident Response Incident Response lifecycle according to AWS. Build IR playbook and automate with Lambda/Step Functions. Sample scenario: exposed IAM keys, S3 public exposure, malware detection on EC2. 3. Learnings Understand the 5 pillars of Security Pillar and Shared Responsibility Model. Apply advanced IAM: Identity Center, SCPs, avoid using long-term credentials. Understand the importance of Data Security: KMS, secrets management. Know how to build and automate Incident Response through serverless workflows. 4. Experience the event The workshop summarizes the learning chain, strengthening the security foundation before completing the project. The IAM Identity Center and Secrets Manager sections directly solve the problem of authentication and API key management of the group. IR scenarios (like S3 public exposure) help reinforce project security policies. Q\u0026amp;A session to further guide the AWS Security Specialty certification path. "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"During my internship, I participated in 4 events, each event was a memorable experience with new, interesting and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: DX Talk#7: Reinventing DevSecOps with AWS Generative AI\nTime: 09:00 October 16, 2025\nLocation: 26th Floor, Bitexco Building, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole in the event: Attendees\nEvent 2 Event Name: AWS Cloud Mastery Series #1 — AI/ML/GenAI on AWS\nTime: 09:00 November 15, 2025\nLocation: 26th Floor, Bitexco Building, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole in the event: Attendees\nEvent 3 Event name: AWS Cloud Mastery Series #2 — DevOps on AWS\nTime: 09:00 November 17, 2025\nLocation: 26th Floor, Bitexco Building, No. 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole in the event: Attendees\nEvent 4 Event name: AWS Cloud Mastery Series #3 — According to AWS Well-Architected Security Pillar\nTime: 09:00 November 29/11/2025\nLocation: 26th Floor, Bitexco Building, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole in the event: Attendees\nEvent 5 Event name: AWS Bedrock, Agent Core \u0026amp; the Future of AI AgentsWell-Architected Security Pillar\nTime: 09:00 November 29/11/2025\nLocation: 26th Floor, Bitexco Building, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole in the event: Attendees\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/5.05-configure-api-lambda/","title":"Configure API &amp; Lambda","tags":[],"description":"","content":"Overview Sau khi deploy infrastructure, bạn cần cấu hình API Gateway routes và Lambda functions để xử lý business logic. Dự án OJT E-commerce sử dụng kiến trúc 2-step deployment: Infrastructure (CDK) và Lambda Code (riêng biệt).\nAPI Architecture API Gateway (REST API) ↓ ┌─────────────────────────────────────────────────────────────────┐ │ 11 Lambda Modules (63 APIs) │ ├─────────┬─────────┬─────────┬─────────┬─────────┬───────────────┤ │ Auth │Products │ Cart │ Orders │Categories│ Brands │ │(4 APIs) │(12 APIs)│(6 APIs) │(9 APIs) │ (6 APIs) │ (5 APIs) │ ├─────────┼─────────┼─────────┼─────────┼─────────┼───────────────┤ │ Banners │ Ratings │ Users │ Images │ Product │ │ │(7 APIs) │(3 APIs) │(3 APIs) │(1 API) │ Details │ │ │ │ │ │ │(7 APIs) │ │ └─────────┴─────────┴─────────┴─────────┴─────────┴───────────────┘ ↓ ↓ ↓ ↓ ↓ RDS SQL Server S3 Images (via Secrets Manager) Step 1: Review Project Structure Lambda Functions Structure:\nOJT_lambda/ ├── shared/ # Shared utilities │ ├── database.js # RDS connection helper │ ├── auth.js # JWT utilities │ └── response.js # API response formatters ├── auth/ # Authentication (4 functions) │ ├── login.js # POST /auth/login │ ├── signup.js # POST /auth/signup │ ├── logout.js # POST /auth/logout │ └── me.js # GET /auth/me ├── products/ # Products (12 functions) │ ├── getProducts.js # GET /products │ ├── getProductDetail.js # GET /products/detail/{id} │ ├── createProduct.js # POST /products │ ├── updateProduct.js # PUT /products/{id} │ ├── deleteProduct.js # DELETE /products/{id} │ ├── searchProducts.js # GET /products/search │ ├── getBestSelling.js # GET /products/best-selling │ ├── getNewest.js # GET /products/newest │ └── ... ├── cart/ # Cart (6 functions) ├── orders/ # Orders (9 functions) ├── categories/ # Categories (6 functions) ├── brands/ # Brands (5 functions) ├── banners/ # Banners (7 functions) ├── ratings/ # Ratings (3 functions) ├── users/ # Users (3 functions) ├── images/ # Images (1 function) └── product-details/ # Product Details (7 functions) Step 2: Configure Lambda Environment Variables 1. Navigate to Lambda project\ncd OJT_lambda 2. Copy environment template\ncopy .env.example .env 3. Edit .env file\n# AWS Configuration AWS_REGION=ap-southeast-1 AWS_ACCOUNT_ID=123456789012 # Database Configuration (from CDK outputs) DB_HOST=ojt-database.xxx.ap-southeast-1.rds.amazonaws.com DB_NAME=demoaws DB_SECRET_ARN=arn:aws:secretsmanager:ap-southeast-1:123456789012:secret:OJT/RDS/Credentials # JWT Configuration JWT_SECRET=your-jwt-secret-key JWT_EXPIRES_IN=7d # S3 Images Bucket (from CDK outputs) S3_IMAGES_BUCKET=ojt-ecommerce-images-123456789012 4. Get values from CDK outputs\n# Get RDS endpoint aws rds describe-db-instances ` --db-instance-identifier ojt-database ` --query \u0026#39;DBInstances[0].Endpoint.Address\u0026#39; ` --output text # Get Secrets Manager ARN aws secretsmanager list-secrets ` --query \u0026#34;SecretList[?contains(Name, \u0026#39;OJT\u0026#39;)].ARN\u0026#34; ` --output text # Get S3 bucket name aws s3 ls | Select-String \u0026#34;ojt-ecommerce-images\u0026#34; Step 3: Review API Endpoints Authentication APIs (4 endpoints):\nMethod Endpoint Handler Description POST /auth/login login.js User login POST /auth/signup signup.js User registration POST /auth/logout logout.js User logout GET /auth/me me.js Get current user Products APIs (12 endpoints):\nMethod Endpoint Handler Description GET /products getProducts.js List all products GET /products/detail/{id} getProductDetail.js Product detail POST /products createProduct.js Create product (Admin) PUT /products/{id} updateProduct.js Update product (Admin) DELETE /products/{id} deleteProduct.js Delete product (Admin) GET /products/search searchProducts.js Search products GET /products/best-selling getBestSelling.js Best selling products GET /products/newest getNewest.js Newest products GET /products/category/{id} getProductsByCategory.js Products by category GET /products/brand/{id} getProductsByBrand.js Products by brand GET /products/price-range getProductsByPriceRange.js Products by price Cart APIs (6 endpoints):\nMethod Endpoint Handler Description POST /cart addToCart.js Add to cart GET /cart/me getMyCart.js Get user\u0026rsquo;s cart PUT /cart/{id} updateCartItem.js Update cart item DELETE /cart/{id} removeCartItem.js Remove cart item DELETE /cart clearCart.js Clear cart GET /cart/count getCartCount.js Get cart count Orders APIs (9 endpoints):\nMethod Endpoint Handler Description GET /orders getAllOrders.js All orders (Admin) POST /orders createOrder.js Create order POST /orders/create-cod createOrderCOD.js Create COD order GET /orders/{id}/details getOrderDetails.js Order details GET /orders/user/{userId} getUserOrders.js User\u0026rsquo;s orders PATCH /orders/{id}/status updateOrderStatus.js Update status DELETE /orders/{id} cancelOrder.js Cancel order Step 4: Install Lambda Dependencies # Install main dependencies cd OJT_lambda npm install # Install all module dependencies npm run install:all This installs dependencies for:\nshared/ - Database, auth, response utilities auth/ - bcryptjs, jsonwebtoken products/ - Database queries cart/, orders/, etc. Step 5: Review Shared Utilities Database Helper (shared/database.js):\nconst sql = require(\u0026#39;mssql\u0026#39;); const config = { server: process.env.DB_HOST, database: process.env.DB_NAME, user: process.env.DB_USERNAME, password: process.env.DB_PASSWORD, options: { encrypt: true, trustServerCertificate: true } }; async function query(sqlQuery, params = []) { const pool = await sql.connect(config); const result = await pool.request(); // Add parameters params.forEach((param, index) =\u0026gt; { result.input(`param${index}`, param); }); return result.query(sqlQuery); } module.exports = { query, sql }; Auth Helper (shared/auth.js):\nconst jwt = require(\u0026#39;jsonwebtoken\u0026#39;); function generateToken(user) { return jwt.sign( { userId: user.UserID, email: user.Email, role: user.Role }, process.env.JWT_SECRET, { expiresIn: process.env.JWT_EXPIRES_IN || \u0026#39;7d\u0026#39; } ); } function verifyToken(token) { return jwt.verify(token, process.env.JWT_SECRET); } module.exports = { generateToken, verifyToken }; Response Helper (shared/response.js):\nfunction success(data, statusCode = 200) { return { statusCode, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify(data) }; } function error(message, statusCode = 500) { return { statusCode, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, body: JSON.stringify({ error: message }) }; } module.exports = { success, error }; Step 6: Verify API Gateway Configuration 1. Get API Gateway URL from CDK outputs\n# Get API Gateway URL aws cloudformation describe-stacks ` --stack-name OJT-ApiStack ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue\u0026#39; ` --output text Expected output:\nhttps://xxxxxxxxxx.execute-api.ap-southeast-1.amazonaws.com/prod 2. Check API Gateway resources\n# Get API ID $API_ID = aws apigateway get-rest-apis ` --query \u0026#34;items[?contains(name, \u0026#39;OJT\u0026#39;)].id\u0026#34; ` --output text # List resources aws apigateway get-resources --rest-api-id $API_ID Step 7: Verify Lambda Functions 1. List Lambda functions\naws lambda list-functions ` --query \u0026#34;Functions[?contains(FunctionName, \u0026#39;OJT-Ecommerce\u0026#39;)].FunctionName\u0026#34; ` --output table Expected output:\nOJT-Ecommerce-AuthModule OJT-Ecommerce-ProductsModule OJT-Ecommerce-ProductDetailsModule OJT-Ecommerce-CartModule OJT-Ecommerce-OrdersModule OJT-Ecommerce-CategoriesModule OJT-Ecommerce-BrandsModule OJT-Ecommerce-BannersModule OJT-Ecommerce-RatingsModule OJT-Ecommerce-UsersModule OJT-Ecommerce-ImagesModule 2. Check Lambda environment variables\naws lambda get-function-configuration ` --function-name OJT-Ecommerce-AuthModule ` --query \u0026#39;Environment.Variables\u0026#39; Step 8: Test Lambda Functions Locally 1. Test Auth Login\ncd OJT_lambda # Test login handler node -e \u0026#34; const handler = require(\u0026#39;./auth/login.js\u0026#39;).handler; const event = { body: JSON.stringify({ email: \u0026#39;test@test.com\u0026#39;, password: \u0026#39;Test123!\u0026#39; }) }; handler(event).then(console.log); \u0026#34; 2. Test Products List\n# Test get products handler node -e \u0026#34; const handler = require(\u0026#39;./products/getProducts.js\u0026#39;).handler; const event = { queryStringParameters: { page: \u0026#39;1\u0026#39;, limit: \u0026#39;10\u0026#39; } }; handler(event).then(console.log); \u0026#34; Step 9: Build Lambda Packages # Build all Lambda packages npm run build # Or build specific module npm run build:auth npm run build:products This creates ZIP files in build/ directory:\nbuild/ ├── auth.zip ├── products.zip ├── product-details.zip ├── cart.zip ├── orders.zip ├── categories.zip ├── brands.zip ├── banners.zip ├── ratings.zip ├── users.zip └── images.zip Configuration Checklist Lambda project structure reviewed Environment variables configured in .env Database connection details obtained from CDK outputs JWT secret configured S3 bucket name configured Dependencies installed (npm install + npm run install:all) Shared utilities reviewed (database, auth, response) API Gateway URL obtained Lambda functions listed and verified Local tests passing Lambda packages built (npm run build) API Summary Module Functions Endpoints Auth 4 login, signup, logout, me Products 12 CRUD + search, filter, best-selling, newest Product Details 7 CRUD + images upload Cart 6 add, get, update, remove, clear, count Orders 9 CRUD + COD, status, date-range Categories 6 CRUD + search Brands 5 CRUD Banners 7 CRUD + toggle Ratings 3 get, stats, create Users 3 getAll, getById, updateProfile Images 1 upload Total 63 Next Steps Once configuration is complete, proceed to [Deploy Backend] to deploy your Lambda code to AWS.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Building Furious Five Fashion: AWS Full-Stack Infrastructure Workshop Overview The system architecture is built on a full-stack serverless model on AWS, focusing on automatic scalability, multi-layer security and cost optimization. All frontend – backend – data – AI – security components operate in a private environment, connected through VPC, PrivateLink and AWS management services\nYou will deploy seven CDK stacks linked together to create a scalable, secure and cost-optimized application:\nFrontend Layer – Deploy the interface on Amplify and distribute content via CloudFront.\nRouting \u0026amp; Protection – Protect access with Route 53, WAF and ACM SSL certificates.\nAuthentication Layer – Create a Cognito User Pool and integrate authentication for API Gateway.\nAPI Layer – Build a private API Gateway to securely communicate with the backend.\nCompute Layer – Run business logic using Lambda functions inside a private VPC.\nStorage Layer – Store static data and uploads on S3 via VPC Endpoint.\nData Layer – Run RDS in a private subnet and control access using IAM/SG.\nAI Layer – Integrate Amazon Bedrock to handle AI tasks via PrivateLink.\nSecurity \u0026amp; Observability – Monitor the entire system using CloudWatch, send alerts via SNS and manage security using IAM.\nContent Workshop Overview Setup Environment CDK Bootstrap Configure Infrastructure Stacks Configure API \u0026amp; Lambda Deploy Backend Services Test Endpoints End-to-End Push to GitLab Clean up "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Continue learning AWS services\nContinue working on the Project\nTasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Serverless Automation with AWS Lambda - Advanced Monitoring with CloudWatch and Grafana 06/10/2025 06/10/2025 3 - CloudWatch Advanced Workshop - Resource Organization with Tags and Resource Groups 07/10/2025 07/10/2025 4 - Access Control with IAM and Resource Tags - Systems Management with AWS Systems Manager 08/10/2025 08/10/2025 5 - Remote Server Access with Systems Manager Session Manager - Infrastructure as Code with AWS CloudFormation - Cloud Development Kit (AWS CDK) Essentials 09/10/2025 09/10/2025 6 - AWS CDK Advanced - Infrastructure as Code Workshop Series - Right-Sizing with EC2 Resource Optimization 10/10/2025 10/10/2025 Week 5 Achievements: Understanding and mastering core concepts Understood the concept of Serverless Computing and how AWS Lambda operates based on event-driven architecture.\nMastered advanced monitoring services such as Amazon CloudWatch and Grafana for system performance tracking.\nUnderstood how to organize and classify resources using Tags and Resource Groups.\nMastered Access Control with IAM Policies combined with Resource Tags to ensure the Least Privilege Principle.\nLearned centralized system management using AWS Systems Manager (Automation, Inventory, Compliance).\nUnderstood secure remote server access through Systems Manager Session Manager without the need for SSH keys.\nMastered the concept and process of Infrastructure as Code (IaC) through AWS CloudFormation and AWS CDK.\nDistinguished between and applied CDK Essentials and CDK Advanced for infrastructure reuse and extensibility.\nUnderstood and applied Right-Sizing \u0026amp; Resource Optimization in EC2 to save costs and enhance performance.\nHands-on practice and configuration on AWS Created and configured Lambda functions to automate tasks such as log processing or data backup.\nSet up CloudWatch Dashboards, Metrics, Logs, and Alarms to monitor EC2, RDS, and Lambda performance.\nConnected Amazon Managed Grafana for visualizing CloudWatch data.\nCreated and applied consistent Resource Tags to group resources by project, environment, and cost center.\nConfigured IAM Policies with conditional tags for precise access control.\nSet up AWS Systems Manager to manage versions, execute Automation Documents, and verify Compliance.\nUsed Session Manager to access EC2 instances without opening SSH ports, ensuring security.\nDeployed CloudFormation Templates (YAML/JSON) to automate infrastructure creation including EC2, S3, IAM Roles, and Security Groups.\nDeveloped and deployed infrastructure using AWS CDK (Python/TypeScript) with Constructs and Stacks for source organization.\nCompleted CDK Workshop Series to create automated deployment pipelines for multiple environments (dev, test, prod).\nUsed Compute Optimizer and Cost Explorer to identify optimal EC2 instance types and recommend right-sizing strategies.\nAchieved results Mastered automation tools for managing and deploying AWS infrastructure (Lambda, CloudFormation, CDK).\nLearned to monitor, analyze, and optimize resources using CloudWatch, Grafana, and Systems Manager.\nAcquired advanced skills in remote access and system orchestration through Session Manager without SSH.\nApplied the Least Privilege Principle effectively in IAM policy design.\nLearned to optimize EC2 cost and performance based on real-time data analysis.\nReady to deploy flexible, automated, and cost-efficient AWS infrastructure environments.\nIntegration and expansion Combined AWS Management Console with AWS CLI/CDK for parallel resource management.\nDeveloped the ability to analyze logs, create alerts, and automate responses using Lambda + CloudWatch Events.\nReady to expand into DevOps pipelines (CodePipeline, CodeBuild) and multi-layer security (KMS, SCPs).\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/4-eventparticipated/4.5-event5/","title":"Event 5","tags":[],"description":"","content":"AWS Bedrock, Agent Core \u0026amp; the Future of AI Agents Event Overview A comprehensive workshop on AWS Bedrock and Agent Core, exploring the present and future of AI agents, AWS\u0026rsquo;s vision, and solutions for deploying agents into production efficiently.\nHighlights Part 1: The Future of AI Agents \u0026amp; AWS Vision The Future of AI Agents\nMoving from experimental prototypes to production-ready solutions Enterprise adoption requires strong governance, security, and scalability Multi-agent orchestration and collaboration become the norm Cost optimization and resource efficiency are key challenges Part 2: AI Agent Models \u0026amp; Security Core Capabilities\nPlatform models: Claude, Titan, Llama with multi-modal support Security: data encryption, VPC endpoints, IAM policies, audit logging Challenges: Putting agents into production remains difficult Part 3: AWS Bedrock Agent Core Core Components\nRuntime: Agent execution, context management, support async/sync Agent Gateway: Centralized entry point, request routing, authentication Memory: Short-term conversational memory, long-term knowledge base Browser/Web: Web scraping, data extraction, real-time retrieval Code Interpreter: Secure code execution (Python, Node.js), API integration Observability: Real-time monitoring, performance metrics, cost insights Part 4: Diaflow - Business-Centric Agent Workflow Founder: Viet (Co-founder of Diaflow)\nUnique Value Proposition\nBusiness-centric design Low-code development for rapid agent creation Enterprise integration with existing business systems Ready-made templates for common business workflows Cost-effectiveness through resource optimization Key Differentiators\nFocus Focus on ROI and business metrics Easier onboarding for non-technical stakeholders Domain-specific expertise and best practices Part 5: CloudThinker - AI Operations Management Key Focus: Cost \u0026amp; Risk Management\nCost Optimization\nResource utilization tracking and optimization Model selection based on cost/performance tradeoffs Batch processing for non-real-time workloads Caching strategies to reduce API calls Budget controls and spend alerts Risk Management\nModel behavior monitoring and anomaly detection Fallback and degradation strategies Guardrails and output validation Regulatory and legal compliance Incident response and disaster recovery Key Benefits\nReduce operational costs by 30-50% Reduce incidents production and risk Improve agent reliability and consistency Enable confident deployment at scale "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/5.06-deploy-backend/","title":"Deploy Backend Services","tags":[],"description":"","content":"Overview Dự án OJT E-commerce sử dụng kiến trúc 2-step deployment: Infrastructure (CDK) và Lambda Code (riêng biệt). Trong bước này, bạn sẽ deploy cả infrastructure và Lambda code.\nDeployment Architecture ┌─────────────────────────────────────────────────────────────┐ │ 2-Step Deployment │ ├─────────────────────────────────────────────────────────────┤ │ Step 1: Deploy Infrastructure (CDK) │ │ ├─ NetworkStack: VPC, Subnets, NAT Gateway │ │ ├─ StorageStack: S3 Buckets │ │ ├─ AuthStack: Cognito (optional) │ │ ├─ DatabaseStack: RDS SQL Server │ │ ├─ ApiStack: API Gateway + Placeholder Lambda │ │ ├─ FrontendStack: S3 + CloudFront │ │ └─ MonitoringStack: CloudWatch │ ├─────────────────────────────────────────────────────────────┤ │ Step 2: Deploy Lambda Code │ │ └─ 11 Lambda Modules (63 APIs) → Update function code │ └─────────────────────────────────────────────────────────────┘ Lambda Modules (11 modules - 63 APIs) Module Functions Description Auth 4 Login, Signup, Logout, Me Products 12 CRUD, Search, Filter ProductDetails 7 CRUD, Images Cart 6 Add, Get, Update, Remove Orders 9 CRUD, COD, Status Categories 6 CRUD, Search Brands 5 CRUD Banners 7 CRUD, Toggle Ratings 3 Get, Stats, Create Users 3 GetAll, GetById, Update Images 1 Upload to S3 Step 1: Deploy Infrastructure (CDK) 1.1 Navigate to Infrastructure Directory cd OJT_infrastructure 1.2 Install Dependencies npm install 1.3 Build TypeScript npm run build 1.4 Deploy Core Stacks # Deploy Network, Storage, Auth, Database stacks npm run deploy:core Expected output:\nOJT-NetworkStack OJT-StorageStack OJT-AuthStack OJT-DatabaseStack Outputs: OJT-NetworkStack.VpcId = vpc-0123456789abcdef0 OJT-DatabaseStack.DbEndpoint = ojt-database.xxx.ap-southeast-1.rds.amazonaws.com OJT-StorageStack.ImagesBucketName = ojt-ecommerce-images-123456789012 Deploy time: ~15-20 minutes (RDS takes longest)\nScreenshot: CDK deploying core stacks\n1.5 Deploy API Stack # Deploy API Gateway + Placeholder Lambda npm run deploy:api Expected output:\n✅ OJT-ApiStack Outputs: OJT-ApiStack.ApiUrl = https://xxxxxxxxxx.execute-api.ap-southeast-1.amazonaws.com/prod OJT-ApiStack.AuthModuleName = OJT-Ecommerce-AuthModule OJT-ApiStack.ProductsModuleName = OJT-Ecommerce-ProductsModule ... Deploy time: ~3-5 minutes\nScreenshot: CDK deploying API stack\n1.6 Verify CDK Deployment # List all deployed stacks aws cloudformation list-stacks ` --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE ` --query \u0026#34;StackSummaries[?contains(StackName, \u0026#39;OJT\u0026#39;)].StackName\u0026#34; ` --output table Expected output:\n--------------------------------- | ListStacks | +-------------------------------+ | OJT-NetworkStack | | OJT-StorageStack | | OJT-AuthStack | | OJT-DatabaseStack | | OJT-ApiStack | +-------------------------------+ Step 2: Deploy Lambda Code Sau khi CDK deploy xong, Lambda functions có placeholder code. Bây giờ deploy actual code.\n2.1 Navigate to Lambda Directory cd ..\\OJT_lambda 2.2 Install Dependencies # Install main dependencies npm install # Install all module dependencies npm run install:all 2.3 Configure Environment # Copy environment template copy .env.example .env # Edit .env with CDK outputs notepad .env Update .env with values from CDK outputs:\n# AWS Configuration AWS_REGION=ap-southeast-1 AWS_ACCOUNT_ID=123456789012 # Database (from OJT-DatabaseStack outputs) DB_HOST=ojt-database.xxx.ap-southeast-1.rds.amazonaws.com DB_NAME=demoaws DB_SECRET_ARN=arn:aws:secretsmanager:ap-southeast-1:123456789012:secret:OJT/RDS/Credentials # JWT JWT_SECRET=your-jwt-secret-key JWT_EXPIRES_IN=7d # S3 (from OJT-StorageStack outputs) S3_IMAGES_BUCKET=ojt-ecommerce-images-123456789012 2.4 Build Lambda Packages # Build all Lambda packages npm run build Expected output:\nBuilding auth module... Done Building products module... Done Building product-details module... Done Building cart module... Done Building orders module... Done Building categories module... Done Building brands module... Done Building banners module... Done Building ratings module... Done Building users module... Done Building images module... Done Build completed! ZIP files in build/ directory. Build creates:\nbuild/ ├── auth.zip (~500 KB) ├── products.zip (~600 KB) ├── product-details.zip (~550 KB) ├── cart.zip (~450 KB) ├── orders.zip (~500 KB) ├── categories.zip (~400 KB) ├── brands.zip (~350 KB) ├── banners.zip (~400 KB) ├── ratings.zip (~350 KB) ├── users.zip (~400 KB) └── images.zip (~300 KB) 2.5 Deploy Lambda Code # Deploy all Lambda functions npm run deploy Expected output:\nDeploying auth module to OJT-Ecommerce-AuthModule... Done Deploying products module to OJT-Ecommerce-ProductsModule... Done Deploying product-details module to OJT-Ecommerce-ProductDetailsModule... Done Deploying cart module to OJT-Ecommerce-CartModule... Done Deploying orders module to OJT-Ecommerce-OrdersModule... Done Deploying categories module to OJT-Ecommerce-CategoriesModule... Done Deploying brands module to OJT-Ecommerce-BrandsModule... Done Deploying banners module to OJT-Ecommerce-BannersModule... Done Deploying ratings module to OJT-Ecommerce-RatingsModule... Done Deploying users module to OJT-Ecommerce-UsersModule... Done Deploying images module to OJT-Ecommerce-ImagesModule... Done All Lambda functions deployed successfully! Deploy time: ~1-2 minutes\nScreenshot: Lambda code deployment\nStep 3: Verify Lambda Deployment 3.1 List Lambda Functions aws lambda list-functions ` --query \u0026#34;Functions[?contains(FunctionName, \u0026#39;OJT-Ecommerce\u0026#39;)].{Name:FunctionName,Runtime:Runtime,Updated:LastModified}\u0026#34; ` --output table Expected output:\n-------------------------------------------------------------------- | ListFunctions | +----------------------------------+------------+------------------+ | Name | Runtime | Updated | +----------------------------------+------------+------------------+ | OJT-Ecommerce-AuthModule | nodejs20.x | 2025-12-09T... | | OJT-Ecommerce-ProductsModule | nodejs20.x | 2025-12-09T... | | OJT-Ecommerce-ProductDetailsModule | nodejs20.x | 2025-12-09T...| | OJT-Ecommerce-CartModule | nodejs20.x | 2025-12-09T... | | OJT-Ecommerce-OrdersModule | nodejs20.x | 2025-12-09T... | | OJT-Ecommerce-CategoriesModule | nodejs20.x | 2025-12-09T... | | OJT-Ecommerce-BrandsModule | nodejs20.x | 2025-12-09T... | | OJT-Ecommerce-BannersModule | nodejs20.x | 2025-12-09T... | | OJT-Ecommerce-RatingsModule | nodejs20.x | 2025-12-09T... | | OJT-Ecommerce-UsersModule | nodejs20.x | 2025-12-09T... | | OJT-Ecommerce-ImagesModule | nodejs20.x | 2025-12-09T... | +----------------------------------+------------+------------------+ 3.2 Check Function Configuration # Check Auth Module configuration aws lambda get-function-configuration ` --function-name OJT-Ecommerce-AuthModule ` --query \u0026#39;{Runtime:Runtime,Handler:Handler,Timeout:Timeout,Memory:MemorySize}\u0026#39; Expected output:\n{ \u0026#34;Runtime\u0026#34;: \u0026#34;nodejs20.x\u0026#34;, \u0026#34;Handler\u0026#34;: \u0026#34;index.handler\u0026#34;, \u0026#34;Timeout\u0026#34;: 30, \u0026#34;Memory\u0026#34;: 128 } 3.3 Verify Code Updated # Check code SHA256 (changes when code updates) aws lambda get-function ` --function-name OJT-Ecommerce-AuthModule ` --query \u0026#39;Configuration.CodeSha256\u0026#39; Step 4: Test Lambda Functions 4.1 Test Auth Login # Invoke Auth Module aws lambda invoke ` --function-name OJT-Ecommerce-AuthModule ` --payload \u0026#39;{\\\u0026#34;httpMethod\\\u0026#34;:\\\u0026#34;POST\\\u0026#34;,\\\u0026#34;path\\\u0026#34;:\\\u0026#34;/auth/login\\\u0026#34;,\\\u0026#34;body\\\u0026#34;:\\\u0026#34;{\\\\\\\u0026#34;email\\\\\\\u0026#34;:\\\\\\\u0026#34;test@test.com\\\\\\\u0026#34;,\\\\\\\u0026#34;password\\\\\\\u0026#34;:\\\\\\\u0026#34;Test123!\\\\\\\u0026#34;}\\\u0026#34;}\u0026#39; ` response.json # Check response Get-Content response.json 4.2 Test Products List # Invoke Products Module aws lambda invoke ` --function-name OJT-Ecommerce-ProductsModule ` --payload \u0026#39;{\\\u0026#34;httpMethod\\\u0026#34;:\\\u0026#34;GET\\\u0026#34;,\\\u0026#34;path\\\u0026#34;:\\\u0026#34;/products\\\u0026#34;,\\\u0026#34;queryStringParameters\\\u0026#34;:{\\\u0026#34;page\\\u0026#34;:\\\u0026#34;1\\\u0026#34;,\\\u0026#34;limit\\\u0026#34;:\\\u0026#34;10\\\u0026#34;}}\u0026#39; ` response.json # Check response Get-Content response.json 4.3 Test via API Gateway # Get API URL $apiUrl = aws cloudformation describe-stacks ` --stack-name OJT-ApiStack ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue\u0026#39; ` --output text # Test products endpoint Invoke-RestMethod -Uri \u0026#34;$apiUrl/products\u0026#34; -Method Get Step 5: Check CloudWatch Logs 5.1 Tail Logs Real-time # Tail Auth Module logs aws logs tail /aws/lambda/OJT-Ecommerce-AuthModule --follow 5.2 View Recent Logs # View last 10 minutes aws logs tail /aws/lambda/OJT-Ecommerce-AuthModule --since 10m 5.3 Search for Errors # Search for errors aws logs filter-log-events ` --log-group-name /aws/lambda/OJT-Ecommerce-AuthModule ` --filter-pattern \u0026#34;ERROR\u0026#34; Screenshot: CloudWatch Logs showing Lambda execution\nStep 6: Deploy Frontend \u0026amp; Monitoring (Optional) 6.1 Deploy Frontend Stack cd ..\\OJT_infrastructure npm run deploy:frontend 6.2 Deploy Monitoring Stack npm run deploy:monitoring Deployment Summary Time Estimates Step Time Notes CDK Deploy Core 15-20 min RDS takes longest CDK Deploy API 3-5 min API Gateway + Lambda Lambda Build 1-2 min ZIP packages Lambda Deploy 1-2 min Update function code Total ~25 min First deployment Update Lambda Code Only Khi chỉ thay đổi Lambda code (không thay đổi infrastructure):\ncd OJT_lambda # Build and deploy (skip CDK) npm run build npm run deploy # Time: ~2-3 minutes Deployment Checklist Infrastructure (CDK) NetworkStack deployed (VPC, Subnets, NAT Gateway) StorageStack deployed (S3 Buckets) AuthStack deployed (Cognito - optional) DatabaseStack deployed (RDS SQL Server) ApiStack deployed (API Gateway + Placeholder Lambda) Lambda Code Dependencies installed (npm install + npm run install:all) Environment configured (.env file) Lambda packages built (npm run build) Lambda code deployed (npm run deploy) Verification All 11 Lambda functions listed Runtime: nodejs20.x Code SHA256 updated Test invocations successful API Gateway responding CloudWatch logs showing executions Troubleshooting Issue: CDK Deploy Fails # Check AWS credentials aws sts get-caller-identity # Check CDK version cdk --version # Clean and rebuild Remove-Item -Recurse -Force node_modules, cdk.out npm install npm run build Issue: Lambda Deploy Fails # Check function exists aws lambda list-functions | Select-String \u0026#34;OJT-Ecommerce\u0026#34; # Check ZIP file created Get-ChildItem build/*.zip # Rebuild and redeploy npm run build npm run deploy Issue: Function Timeout # Increase timeout aws lambda update-function-configuration ` --function-name OJT-Ecommerce-AuthModule ` --timeout 60 Issue: Database Connection Error # Verify RDS endpoint aws rds describe-db-instances ` --db-instance-identifier ojt-database ` --query \u0026#39;DBInstances[0].Endpoint\u0026#39; # Check Security Group allows Lambda aws ec2 describe-security-groups ` --filters \u0026#34;Name=group-name,Values=*OJT*RDS*\u0026#34; Next Steps Backend đã deployed thành công! Tiếp theo:\nTest Endpoints: Verify tất cả 63 API endpoints → Deploy Frontend: React application → Monitor: CloudWatch dashboards → "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Midterm review is intense Continue studying AWS services Working on the Project: Integrating AI into the website Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - - Network Monitoring with VPC Flow Logs - Billing Console Delegationv 13/10/2025 13/10/2025 3 - Managing Quotas with Service Quotas - Cost and Usage Management 14/10/2025 14/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Snapshot Automation with Amazon EBS Data Lifecycle Manager - Anomaly Detection for EBS Backups 15/10/2025 15/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Development Environment with AWS Toolkit for VS Code - Identity Federation with AWS Single Sign-On 16/10/2025 16/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - 17/10/2025 17/10/2025 https://cloudjourney.awsstudygroup.com/ Week 6 Achievements: Understanding AWS Services\nMonitoring \u0026amp; Logging: Track network and system activity through VPC Flow Logs and CloudWatch Logs.\nBilling \u0026amp; Cost Management: Manage finances, delegate billing access, and monitor spending.\nQuota Management: Control and request resource increases via Service Quotas.\nAutomation \u0026amp; Lifecycle: Automate snapshot creation and lifecycle management with EBS Data Lifecycle Manager.\nDevelopment Tools: Develop and deploy applications directly from VS Code using AWS Toolkit.\nIdentity \u0026amp; Access: Centralized access management through AWS Single Sign-On (IAM Identity Center).\nAWS Resource Practice and Operations\nNetwork Monitoring:\nEnabled VPC Flow Logs to monitor network traffic within the VPC.\nLogged data into CloudWatch Logs, filtered and analyzed it to detect abnormal EC2 connections.\nCost \u0026amp; Quota Management:\nReviewed and requested resource limit increases via Service Quotas.\nApplied IAM Policies to restrict access by Region, instance type, and volume type for better cost control.\nGranted Billing access to IAM users, monitored invoices, and reviewed cost reports through the Billing Console.\nBackup Automation:\nCreated EBS Snapshots and configured Data Lifecycle Manager (DLM) to automate backup, archiving, and deletion of old snapshots.\nSet up multi-level snapshot schedules (daily/weekly) to optimize storage costs.\nAnomaly Detection:\nApplied Anomaly Detection in CloudWatch or DLM to monitor unusual backup activities, ensuring data integrity. Development Environment:\nConnected AWS to VS Code for deploying, monitoring, and managing resources without using the AWS Console.\nDebugged and deployed serverless applications directly within the IDE.\nCentralized Identity Federation:\nConfigured AWS IAM Identity Center (SSO) to enable users to access multiple AWS accounts through a single portal.\nOrganized accounts under Organizational Units and assigned permissions to each group or project.\nAchievements Mastered how to:\nMonitor networks, traffic, and system logs using VPC Flow Logs.\nManage and optimize AWS operating costs.\nControl and track resources via Service Quotas.\nAutomate backups using EBS Data Lifecycle Manager.\nSet up AWS development environments directly in VS Code.\nCentrally manage users and access through IAM Identity Center.\nSuccessfully connected and utilized AWS Console, AWS CLI, and AWS Toolkit for VS Code in parallel.\nConclusion Through these lessons, a complete AWS system management workflow was established, covering:\nMonitoring – Cost Management – Quota Control – Automation – Identity – Application Development.\nThis integrated approach enables efficient AWS infrastructure operation, minimizes risks, enhances security, and optimizes resource usage.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"During my internship at Amazon Web Services Vietnam Co., Ltd. from 8/9/2025 to 12/9/2025, I had the opportunity to learn, practice, and apply the knowledge acquired in school to a real-world working environment.\nI participated in First Cloud Journey, through which I improved my skills in Communication, financial management, more knowledge about AWS and Cloud: translation.\nIn terms of work ethic, I always strived to complete tasks well, complied with workplace regulations, and actively engaged with colleagues to improve work efficiency.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ✅ ☐ ☐ 2 Ability to learn Ability to absorb new knowledge and learn quickly ☐ ✅ ☐ 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ✅ ☐ ☐ 4 Sense of responsibility Completing tasks on time and ensuring quality ✅ ☐ ☐ 5 Discipline Adhering to schedules, rules, and work processes ☐ ✅ ☐ 6 Progressive mindset Willingness to receive feedback and improve oneself ✅ ☐ ☐ 7 Communication Presenting ideas and reporting work clearly ☐ ✅ ☐ 8 Teamwork Working effectively with colleagues and participating in teams ✅ ☐ ☐ 9 Professional conduct Respecting colleagues, partners, and the work environment ✅ ☐ ☐ 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ☐ ✅ ☐ 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ☐ ✅ ☐ 12 Overall General evaluation of the entire internship period ☐ ✅ ☐ Needs Improvement Improve self-discipline and strictly comply with the company’s regulations. Enhance problem-solving thinking. Learn to handle situations more quickly and safely. Set clearer goals "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/5.07-test-endpoints/","title":"Test Endpoints End-to-End","tags":[],"description":"","content":"Overview Sau khi deploy backend thành công, bạn cần test tất cả API endpoints để đảm bảo hệ thống hoạt động đúng. Workshop này hướng dẫn chi tiết cách test từng module của hệ thống OJT E-commerce.\nAPI Architecture API Gateway (REST API) ↓ ┌─────────────────────────────────────────────────────────────────┐ │ 11 Lambda Modules (63 APIs) │ ├─────────┬─────────┬─────────┬─────────┬─────────┬───────────────┤ │ Auth │Products │ Cart │ Orders │Categories│ Brands │ │(4 APIs) │(12 APIs)│(6 APIs) │(9 APIs) │ (6 APIs) │ (5 APIs) │ ├─────────┼─────────┼─────────┼─────────┼─────────┼───────────────┤ │ Banners │ Ratings │ Users │ Images │ Product │ │ │(7 APIs) │(3 APIs) │(3 APIs) │(1 API) │ Details │ │ │ │ │ │ │(7 APIs) │ │ └─────────┴─────────┴─────────┴─────────┴─────────┴───────────────┘ ↓ RDS SQL Server (via Secrets Manager) Step 1: Get API Endpoint 1. Get API URL from CloudFormation Outputs\n# Get API endpoint from API Stack $API_URL = aws cloudformation describe-stacks ` --stack-name OJT-ApiStack ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiUrl`].OutputValue\u0026#39; ` --output text Write-Host \u0026#34;API Endpoint: $API_URL\u0026#34; # Output: https://xxxxxxxxxx.execute-api.ap-southeast-1.amazonaws.com/prod 2. Setup Environment Variables\n# Set API endpoint for PowerShell session $API_URL = \u0026#34;https://xxxxxxxxxx.execute-api.ap-southeast-1.amazonaws.com/prod\u0026#34; Write-Host \u0026#34;API Endpoint configured: $API_URL\u0026#34; Step 2: Test Authentication APIs 2.1 Test User Signup # POST /auth/signup $signupBody = @{ email = \u0026#34;testuser@example.com\u0026#34; password = \u0026#34;Test123!\u0026#34; fullName = \u0026#34;Test User\u0026#34; phone = \u0026#34;+84901234567\u0026#34; } | ConvertTo-Json $response = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/auth/signup\u0026#34; ` -Method Post ` -ContentType \u0026#34;application/json\u0026#34; ` -Body $signupBody $response | ConvertTo-Json 2.2 Test User Login # POST /auth/login $loginBody = @{ email = \u0026#34;testuser@example.com\u0026#34; password = \u0026#34;Test123!\u0026#34; } | ConvertTo-Json $loginResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/auth/login\u0026#34; ` -Method Post ` -ContentType \u0026#34;application/json\u0026#34; ` -Body $loginBody # Save JWT token for authenticated requests $TOKEN = $loginResponse.token Write-Host \u0026#34;JWT Token: $TOKEN\u0026#34; $loginResponse | ConvertTo-Json # Expected: { \u0026#34;token\u0026#34;: \u0026#34;eyJhbG...\u0026#34;, \u0026#34;user\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;email\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;role\u0026#34;: \u0026#34;Customer\u0026#34; } } 2.3 Test Get Current User # GET /auth/me (requires authentication) $headers = @{ \u0026#34;Authorization\u0026#34; = \u0026#34;Bearer $TOKEN\u0026#34; } $meResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/auth/me\u0026#34; ` -Method Get ` -Headers $headers $meResponse | ConvertTo-Json # Expected: { \u0026#34;user\u0026#34;: { \u0026#34;userId\u0026#34;: 1, \u0026#34;email\u0026#34;: \u0026#34;testuser@example.com\u0026#34;, \u0026#34;fullName\u0026#34;: \u0026#34;Test User\u0026#34; } } Step 3: Test Products APIs 3.1 Get All Products # GET /products $products = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/products?page=1\u0026amp;limit=10\u0026#34; ` -Method Get Write-Host \u0026#34;Found $($products.total) products\u0026#34; $products | ConvertTo-Json -Depth 3 3.2 Get Product Detail # GET /products/detail/{id} $productId = 1 $product = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/products/detail/$productId\u0026#34; ` -Method Get $product | ConvertTo-Json -Depth 3 3.3 Search Products # GET /products/search?q=keyword $searchResults = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/products/search?q=phone\u0026#34; ` -Method Get $searchResults | ConvertTo-Json -Depth 3 3.4 Get Best Selling Products # GET /products/best-selling $bestSelling = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/products/best-selling?limit=10\u0026#34; ` -Method Get $bestSelling | ConvertTo-Json -Depth 3 3.5 Get Newest Products # GET /products/newest $newest = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/products/newest?limit=10\u0026#34; ` -Method Get $newest | ConvertTo-Json -Depth 3 3.6 Get Products by Category # GET /products/category/{id} $categoryId = 1 $categoryProducts = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/products/category/$categoryId\u0026#34; ` -Method Get $categoryProducts | ConvertTo-Json -Depth 3 3.7 Get Products by Brand # GET /products/brand/{id} $brandId = 1 $brandProducts = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/products/brand/$brandId\u0026#34; ` -Method Get $brandProducts | ConvertTo-Json -Depth 3 Step 4: Test Cart APIs 4.1 Add to Cart # POST /cart (requires authentication) $cartBody = @{ productDetailId = 1 quantity = 2 } | ConvertTo-Json $cartResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/cart\u0026#34; ` -Method Post ` -Headers $headers ` -ContentType \u0026#34;application/json\u0026#34; ` -Body $cartBody $cartResponse | ConvertTo-Json 4.2 Get My Cart # GET /cart/me $myCart = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/cart/me\u0026#34; ` -Method Get ` -Headers $headers $myCart | ConvertTo-Json -Depth 3 4.3 Update Cart Item # PUT /cart/{id} $cartItemId = 1 $updateBody = @{ quantity = 3 } | ConvertTo-Json $updateResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/cart/$cartItemId\u0026#34; ` -Method Put ` -Headers $headers ` -ContentType \u0026#34;application/json\u0026#34; ` -Body $updateBody $updateResponse | ConvertTo-Json 4.4 Get Cart Count # GET /cart/count $cartCount = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/cart/count\u0026#34; ` -Method Get ` -Headers $headers Write-Host \u0026#34;Cart items: $($cartCount.count)\u0026#34; 4.5 Remove Cart Item # DELETE /cart/{id} Invoke-RestMethod ` -Uri \u0026#34;$API_URL/cart/$cartItemId\u0026#34; ` -Method Delete ` -Headers $headers Write-Host \u0026#34;Cart item removed\u0026#34; Step 5: Test Orders APIs 5.1 Create Order (COD) # POST /orders/create-cod $orderBody = @{ shippingAddress = \u0026#34;123 Test Street, District 1, Ho Chi Minh City\u0026#34; phone = \u0026#34;+84901234567\u0026#34; note = \u0026#34;Please call before delivery\u0026#34; } | ConvertTo-Json $orderResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/orders/create-cod\u0026#34; ` -Method Post ` -Headers $headers ` -ContentType \u0026#34;application/json\u0026#34; ` -Body $orderBody $ORDER_ID = $orderResponse.orderId Write-Host \u0026#34;Order created: $ORDER_ID\u0026#34; $orderResponse | ConvertTo-Json 5.2 Get Order Details # GET /orders/{id}/details $orderDetails = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/orders/$ORDER_ID/details\u0026#34; ` -Method Get ` -Headers $headers $orderDetails | ConvertTo-Json -Depth 3 5.3 Get User Orders # GET /orders/user/{userId} $userId = 1 $userOrders = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/orders/user/$userId\u0026#34; ` -Method Get ` -Headers $headers $userOrders | ConvertTo-Json -Depth 3 5.4 Update Order Status (Admin) # PATCH /orders/{id}/status $statusBody = @{ status = \u0026#34;Processing\u0026#34; } | ConvertTo-Json $statusResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/orders/$ORDER_ID/status\u0026#34; ` -Method Patch ` -Headers $headers ` -ContentType \u0026#34;application/json\u0026#34; ` -Body $statusBody $statusResponse | ConvertTo-Json Step 6: Test Categories APIs 6.1 Get All Categories # GET /categories $categories = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/categories\u0026#34; ` -Method Get $categories | ConvertTo-Json -Depth 3 6.2 Get Category by ID # GET /categories/{id} $categoryId = 1 $category = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/categories/$categoryId\u0026#34; ` -Method Get $category | ConvertTo-Json 6.3 Search Categories # GET /categories/search?q=keyword $categorySearch = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/categories/search?q=phone\u0026#34; ` -Method Get $categorySearch | ConvertTo-Json Step 7: Test Brands APIs 7.1 Get All Brands # GET /brands $brands = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/brands\u0026#34; ` -Method Get $brands | ConvertTo-Json -Depth 3 7.2 Get Brand by ID # GET /brands/{id} $brandId = 1 $brand = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/brands/$brandId\u0026#34; ` -Method Get $brand | ConvertTo-Json Step 8: Test Banners APIs 8.1 Get All Banners # GET /banners $banners = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/banners\u0026#34; ` -Method Get $banners | ConvertTo-Json -Depth 3 8.2 Get Active Banners # GET /banners?active=true $activeBanners = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/banners?active=true\u0026#34; ` -Method Get $activeBanners | ConvertTo-Json -Depth 3 Step 9: Test Ratings APIs 9.1 Get Product Ratings # GET /ratings/product/{id} $productId = 1 $ratings = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/ratings/product/$productId\u0026#34; ` -Method Get $ratings | ConvertTo-Json -Depth 3 9.2 Get Rating Stats # GET /ratings/product/{id}/stats $ratingStats = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/ratings/product/$productId/stats\u0026#34; ` -Method Get $ratingStats | ConvertTo-Json # Expected: { \u0026#34;averageRating\u0026#34;: 4.5, \u0026#34;totalRatings\u0026#34;: 10, \u0026#34;distribution\u0026#34;: { \u0026#34;5\u0026#34;: 5, \u0026#34;4\u0026#34;: 3, \u0026#34;3\u0026#34;: 2 } } 9.3 Create Rating # POST /ratings $ratingBody = @{ productId = 1 rating = 5 comment = \u0026#34;Great product! Highly recommended.\u0026#34; } | ConvertTo-Json $ratingResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/ratings\u0026#34; ` -Method Post ` -Headers $headers ` -ContentType \u0026#34;application/json\u0026#34; ` -Body $ratingBody $ratingResponse | ConvertTo-Json Step 10: Test Users APIs (Admin) 10.1 Get All Users # GET /users (Admin only) $users = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/users\u0026#34; ` -Method Get ` -Headers $headers $users | ConvertTo-Json -Depth 3 10.2 Get User by ID # GET /users/{id} $userId = 1 $user = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/users/$userId\u0026#34; ` -Method Get ` -Headers $headers $user | ConvertTo-Json 10.3 Update User Profile # PUT /users/profile/{id} $profileBody = @{ fullName = \u0026#34;Updated Name\u0026#34; phone = \u0026#34;+84909876543\u0026#34; address = \u0026#34;456 New Street, District 2\u0026#34; } | ConvertTo-Json $profileResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_URL/users/profile/$userId\u0026#34; ` -Method Put ` -Headers $headers ` -ContentType \u0026#34;application/json\u0026#34; ` -Body $profileBody $profileResponse | ConvertTo-Json Step 11: Test Images Upload API 11.1 Upload Image # POST /images/upload # Note: This requires multipart/form-data # Using curl for file upload curl -X POST \u0026#34;$API_URL/images/upload\u0026#34; ` -H \u0026#34;Authorization: Bearer $TOKEN\u0026#34; ` -F \u0026#34;file=@D:\\test-image.jpg\u0026#34; ` -F \u0026#34;type=product\u0026#34; --- ### Step 12: Verify CloudWatch Logs #### 12.1 Check Lambda Logs ```powershell # Tail Auth Module logs aws logs tail /aws/lambda/OJT-Ecommerce-AuthModule --follow # Tail Products Module logs aws logs tail /aws/lambda/OJT-Ecommerce-ProductsModule --follow # View last 10 minutes aws logs tail /aws/lambda/OJT-Ecommerce-AuthModule --since 10m Testing Checklist Authentication APIs (4 endpoints) POST /auth/signup - User registration POST /auth/login - User login, get JWT token POST /auth/logout - User logout GET /auth/me - Get current user Products APIs (12 endpoints) GET /products - List all products GET /products/detail/{id} - Get product detail GET /products/search - Search products GET /products/best-selling - Best selling products GET /products/newest - Newest products GET /products/category/{id} - Products by category GET /products/brand/{id} - Products by brand GET /products/price-range - Products by price range POST /products - Create product (Admin) PUT /products/{id} - Update product (Admin) DELETE /products/{id} - Delete product (Admin) Cart APIs (6 endpoints) POST /cart - Add to cart GET /cart/me - Get my cart PUT /cart/{id} - Update cart item DELETE /cart/{id} - Remove cart item DELETE /cart - Clear cart GET /cart/count - Get cart count Orders APIs (9 endpoints) POST /orders - Create order POST /orders/create-cod - Create COD order GET /orders/{id}/details - Get order details GET /orders/user/{userId} - Get user orders GET /orders - Get all orders (Admin) PATCH /orders/{id}/status - Update order status DELETE /orders/{id} - Cancel order Categories APIs (6 endpoints) GET /categories - List all categories GET /categories/{id} - Get category by ID GET /categories/search - Search categories POST /categories - Create category (Admin) PUT /categories/{id} - Update category (Admin) DELETE /categories/{id} - Delete category (Admin) Brands APIs (5 endpoints) GET /brands - List all brands GET /brands/{id} - Get brand by ID POST /brands - Create brand (Admin) PUT /brands/{id} - Update brand (Admin) DELETE /brands/{id} - Delete brand (Admin) Banners APIs (7 endpoints) GET /banners - List all banners GET /banners/{id} - Get banner by ID GET /banners?active=true - Get active banners POST /banners - Create banner (Admin) PUT /banners/{id} - Update banner (Admin) DELETE /banners/{id} - Delete banner (Admin) PATCH /banners/{id}/toggle - Toggle banner (Admin) Ratings APIs (3 endpoints) GET /ratings/product/{id} - Get product ratings GET /ratings/product/{id}/stats - Get rating stats POST /ratings - Create rating Users APIs (3 endpoints) GET /users - Get all users (Admin) GET /users/{id} - Get user by ID PUT /users/profile/{id} - Update profile Images API (1 endpoint) POST /images/upload - Upload image Performance Benchmarks Expected Response Times:\nEndpoint Expected Time Notes POST /auth/login \u0026lt; 500ms JWT generation GET /products \u0026lt; 300ms Database query GET /products/detail/{id} \u0026lt; 200ms Single record POST /cart \u0026lt; 300ms Database write POST /orders/create-cod \u0026lt; 500ms Transaction GET /categories \u0026lt; 200ms Cached data POST /images/upload \u0026lt; 2s S3 upload "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Continue studying and becoming familiar with AWS services. No new topics this week—focus on review in preparation for the midterm on October 31. Additional learning through Udemy – CLF-C02 course. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Security Compliance with AWS Security Hub - Private Access to S3 with VPC Endpoints - Application Protection with AWS WAF 20/10/2025 20/10/2025 3 - Encryption with AWS Key Management Service (KMS) - Data Protection with Amazon Macie - Credentials Management with AWS Secrets Manager 21/10/2025 21/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Security Governance with AWS Firewall Manager - Threat Detection with AWS GuardDuty - Systems Patching with EC2 Image Builder 22/10/2025 22/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Cross-Domain Authentication with Amazon Cognito - S3 Security Best Practices - Data Protection with AWS Backup 23/10/2025 23/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Network Integration with VPC Peering - Centralized Network Management with AWS Transit Gateway - Messaging Systems with SQS and SNS 24/10/2025 24/10/2025 https://cloudjourney.awsstudygroup.com/ Week 7 Achievements: AWS Security Hub\nGained understanding of AWS Security Hub’s role in maintaining security compliance across AWS environments.\nFunctions: collects and standardizes findings in the AWS Security Finding Format (ASFF).\nProvides a security score representing the ratio of compliant controls to total active controls.\nEach standard includes multiple controls that continuously scan and assess AWS resources, producing results categorized as Passed, Failed, Unknown, or No data.\nPrivate Access to S3 with VPC Endpoints Established a secure connection from a VPC to AWS services without public IPs or an Internet Gateway.\nGateway Endpoints: used for S3 and DynamoDB, routing internally via route tables.\nInterface Endpoints: use PrivateLink through ENIs and internal DNS.\nConfigured a Gateway Endpoint for S3 and verified connectivity through the CLI without public internet traversal.\nApplication Protection with AWS WAF AWS WAF provides web application firewall capabilities for monitoring and controlling HTTP(S) traffic to CloudFront, ALB, or API Gateway. Core functions: allow or block requests based on IP, query strings, or attack patterns.\nSupports both managed rule groups and custom rule sets.\nIntegrated with AWS Shield, CloudFront, or ALB for comprehensive protection.\nSuccessfully created and attached a Web ACL to a CloudFront distribution.\nEncryption with AWS Key Management Service (KMS) AWS KMS offers centralized key management for encryption operations. Supports symmetric and asymmetric encryption with IAM and key policies for access control.\nIncludes AWS-managed and customer-managed keys (CMKs).\nIntegrated with S3, EBS, RDS, Lambda, and CloudTrail.\nCreated a customer-managed CMK and configured usage permissions.\nData Protection with Amazon Macie Amazon Macie automatically detects, classifies, and protects sensitive data stored in S3. Provides inventory, monitors access control, and alerts on potential data leaks.\nTwo operating modes: Automated Sensitive Data Discovery and Custom Discovery Jobs.\nAll results are encrypted using AWS KMS.\nSuccessfully deployed Macie for automated detection of sensitive data in S3.\nCredentials Management with AWS Secrets Manager AWS Secrets Manager securely manages sensitive credentials such as passwords, API keys, and tokens. Integrates with RDS, Redshift, and DocumentDB for automatic password rotation via Lambda.\nEncrypts secrets with KMS.\nSuccessfully implemented Secrets Manager for secure and automated credential management.\nSecurity Governance with AWS Firewall Manager Centralized policy management service for enforcing consistent firewall configurations across AWS Organizations. Integrates with AWS WAF, Shield Advanced, Security Groups, and VPCs.\nSynchronizes alerts and compliance statuses through Security Hub.\nEnables standardized, organization-wide security control.\nSuccessfully created Firewall Manager to enforce unified firewall policies.\nThreat Detection with AWS GuardDuty GuardDuty uses machine learning and threat intelligence to detect anomalies and potential security threats. Monitors CloudTrail, VPC Flow Logs, and DNS logs for malicious or unauthorized activity.\nDetects reconnaissance, compromised credentials, and communication with malicious domains.\nIntegrates with Security Hub, EventBridge, and Lambda for automated response.\nSuccessfully deployed GuardDuty for continuous threat detection and alerting.\nSystems Patching with EC2 Image Builder Automates the creation, testing, and deployment of secure AMIs. Pipeline stages: source → build → test → distribute.\nSupports custom components for installing software and applying security patches.\nIntegrates with SSM, CloudWatch, and IAM for automation.\nSuccessfully created Image Builder pipeline for secure AMI maintenance.\nCross-Domain Authentication with Amazon Cognito AWS Cognito manages user authentication and authorization. Consists of User Pools for authentication and Identity Pools for temporary AWS access.\nSupports MFA, email verification, password reset, and cross-domain federated sign-in.\nIntegrated with API Gateway, AppSync, and mobile applications.\nSuccessfully deployed Cognito for user authentication and federated access.\nS3 Security Best Practices Implemented security best practices for S3 data protection. Principles: Private by default, Block Public Access, Encryption (SSE-S3/SSE-KMS), and Access Control via IAM/Bucket Policies/ACLs.\nCombined with Macie, GuardDuty, and Security Hub for compliance monitoring.\nSuccessfully configured S3 for secure storage and access management.\nData Protection with AWS Backup AWS Backup provides centralized and automated backup management across AWS resources. Defines Backup Plans, Vaults, and Lifecycle Policies.\nEncrypts all data with KMS and supports cross-region/cross-account backup.\nBackup Audit Manager ensures compliance and visibility.\nSuccessfully created AWS Backup for automated backup and recovery.\nNetwork Integration with VPC Peering Established secure communication between two VPCs using private IPs. Point-to-point, non-transitive connection with low latency and high security.\nSupports inter-region connectivity if CIDR blocks do not overlap.\nConfigured route tables for internal communication across resources.\nSuccessfully created VPC Peering for secure inter-VPC traffic.\nCentralized Network Management with AWS Transit Gateway AWS Transit Gateway acts as a central hub for connecting multiple VPCs, VPNs, and Direct Connect links. Simplifies complex peering meshes with transitive routing capability.\nProvides attachment-based routing tables for granular traffic control.\nSupports multicast, cross-account, cross-region, and high-bandwidth connections.\nIntegrated with AWS Network Manager for monitoring and topology management.\nSuccessfully deployed Transit Gateway for centralized network management.\nMessaging Systems with SQS and SNS Implemented asynchronous messaging architecture using SQS and SNS. SQS: message queue system with Standard and FIFO queues for reliable delivery.\nSNS: publish/subscribe system for distributing notifications across multiple endpoints.\nCombined SNS and SQS for fan-out message distribution.\nEnsures high scalability, reliability, and decoupling of microservices.\nSuccessfully built an asynchronous messaging system using SQS and SNS.\nConclusion\nAll AWS Security services are closely integrated, collectively strengthening cloud defense posture. However, the ecosystem is complex and requires extensive hands-on experience to master.\nFor midterm preparation, six review sections have been completed and continuously revisited.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don’t understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company does not have a policy to provide internship allowances but does offer flexible scheduling when necessary.. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What did you find most satisfying during your internship? Being guided by mentors and shown what to do and what to improve. What do you think the company should improve for future interns? Nothing If recommending to a friend, would you suggest they intern here? Why or why not? Yes, because the FCJ program here is very good and beneficial for the future. Suggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? I hope AWS will allow more frequent access to the office. Would you like to continue this program in the future? Yes, because AWS is a large company and offers many opportunities to participate in labor markets related to AWS "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/5.08-push-gitlab/","title":"Push to GitLab","tags":[],"description":"","content":"Overview Sau khi test thành công, bạn sẽ push code lên GitLab để version control và chuẩn bị cho CI/CD. Dự án OJT E-commerce có 3 phần chính cần quản lý: Infrastructure, Lambda, và Frontend.\nProject Structure OJT/ ├── OJT_infrastructure/ # CDK Infrastructure (TypeScript) ├── OJT_lambda/ # Lambda Functions (JavaScript) ├── OJT_frontendDev/ # Frontend (React + Vite) ├── database/ # Database Scripts └── README.md # Project documentation Step 1: Initialize Git Repository 1. Navigate to Project Root\ncd D:\\AWS\\Src\\OJT 2. Check Git Status\n# Check if Git is already initialized git status # If not initialized: git init 3. Configure Git\n# Set your name and email git config user.name \u0026#34;Your Name\u0026#34; git config user.email \u0026#34;your.email@example.com\u0026#34; # Verify configuration git config --list Step 2: Create .gitignore 1. Create .gitignore File\n# Create .gitignore in project root @\u0026#34; # Dependencies node_modules/ package-lock.json # Build outputs dist/ build/ *.js.map cdk.out/ # Environment variables .env .env.local .env.*.local # AWS *.pem *.key # Deployment packages *.zip # Logs logs/ *.log npm-debug.log* # IDE .vscode/settings.json .idea/ *.swp *.swo # OS .DS_Store Thumbs.db # CDK cdk.context.json # TypeScript *.tsbuildinfo *.d.ts *.js !vite.config.js !eslint.config.js # Lambda build OJT_lambda/build/ \u0026#34;@ | Out-File -FilePath .gitignore -Encoding UTF8 2. Verify .gitignore\nGet-Content .gitignore Step 3: Stage and Commit Files 1. Add Files to Staging\n# Add all files git add . # Check what will be committed git status 2. Review Files to Commit\n# List files to be committed git diff --cached --name-only # Expected files: # OJT_infrastructure/ # OJT_lambda/ # OJT_frontendDev/ # database/ # README.md # .gitignore 3. Create Initial Commit\n# Commit with message git commit -m \u0026#34;Initial commit: OJT E-commerce infrastructure and backend\u0026#34; # Verify commit git log --oneline ### Step 4: Create GitLab Repository **1. Login to GitLab** Go to https://gitlab.com/ and login with your account. **2. Create New Project** 1. Click **\u0026#34;New project\u0026#34;** 2. Choose **\u0026#34;Create blank project\u0026#34;** 3. Fill in details: - Project name: `ojt-ecommerce` - Project slug: `ojt-ecommerce` - Visibility: **Private** (recommended) - Initialize with README: **No** (we already have code) 4. Click **\u0026#34;Create project\u0026#34;** **3. Copy Repository URL** https://gitlab.com/your-username/ojt-ecommerce.git\n--- ### Step 5: Add Remote and Push **1. Add GitLab Remote** ```powershell # Add remote origin git remote add origin https://gitlab.com/your-username/ojt-ecommerce.git # Verify remote git remote -v 2. Push to GitLab\n# Push to main branch git push -u origin main # If your default branch is \u0026#39;master\u0026#39;: git branch -M main git push -u origin main 3. Enter Credentials\nWhen prompted:\nUsername: Your GitLab username Password: Your GitLab Personal Access Token (not password) Screenshot: Terminal showing successful push\nStep 6: Create Personal Access Token If you don\u0026rsquo;t have a Personal Access Token:\n1. Go to GitLab Settings\nClick your avatar → \u0026ldquo;Preferences\u0026rdquo; Go to \u0026ldquo;Access Tokens\u0026rdquo; in left sidebar 2. Create New Token\nToken name: OJT-Ecommerce-Token Expiration date: Set appropriate date Select scopes: read_repository write_repository Click \u0026ldquo;Create personal access token\u0026rdquo; 3. Save Token\nCopy and save the token securely. You won\u0026rsquo;t be able to see it again.\nStep 7: Verify Push on GitLab 1. Check Repository on GitLab\nGo to your repository: https://gitlab.com/your-username/ojt-ecommerce\n2. Verify Files\nCheck that all files are uploaded:\nOJT_infrastructure/ - CDK Infrastructure OJT_lambda/ - Lambda Functions OJT_frontendDev/ - Frontend database/ - Database Scripts README.md - Documentation .gitignore - Git ignore rules Step 8: Create Development Branch 1. Create dev Branch\n# Create and switch to dev branch git checkout -b dev # Push dev branch to GitLab git push -u origin dev 2. Set Default Branch (Optional)\nOn GitLab:\nGo to Settings → Repository Under Branch defaults, set dev as default branch Step 9: Setup Branch Protection (Optional) 1. Protect Main Branch\nOn GitLab:\nGo to Settings → Repository → Protected branches Add main branch: Allowed to merge: Maintainers Allowed to push: No one Require approval: Yes 2. Protect Dev Branch\nAdd dev branch with similar settings but allow developers to push.\nGit Workflow Summary 1. Create feature branch from dev git checkout dev git pull origin dev git checkout -b feature/new-feature 2. Make changes and commit git add . git commit -m \u0026#34;feat: Add new feature\u0026#34; 3. Push to GitLab git push -u origin feature/new-feature 4. Create Merge Request on GitLab feature/new-feature → dev 5. Review and merge 6. Deploy to dev environment cd OJT_lambda npm run build npm run deploy 7. Test in dev environment 8. Merge dev → main for production Commit Message Convention Follow conventional commits:\nfeat: Add user authentication fix: Fix login validation bug docs: Update API documentation style: Format code with prettier refactor: Refactor database queries test: Add unit tests for auth chore: Update dependencies perf: Optimize product search query Examples:\ngit commit -m \u0026#34;feat: Add cart functionality\u0026#34; git commit -m \u0026#34;fix: Fix order total calculation\u0026#34; git commit -m \u0026#34;docs: Update README with deployment steps\u0026#34; Branch Naming Convention feature/add-cart-api feature/user-authentication bugfix/fix-login-error bugfix/cart-quantity-issue hotfix/critical-security-patch release/v1.0.0 Troubleshooting Issue: Authentication Failed # Use Personal Access Token instead of password # When prompted for password, enter your token # Or configure credential helper git config --global credential.helper store Issue: Large Files Rejected # Check file sizes git ls-files -z | ForEach-Object { $size = (Get-Item $_).Length / 1MB if ($size -gt 1) { Write-Host \u0026#34;$_ : $size MB\u0026#34; } } # Add large files to .gitignore echo \u0026#34;*.zip\u0026#34; \u0026gt;\u0026gt; .gitignore git rm --cached *.zip git commit -m \u0026#34;Remove large files\u0026#34; Issue: Push Rejected (Non-Fast-Forward) # Pull latest changes first git pull origin main --rebase # Then push git push origin main Issue: Merge Conflicts # Update your branch git checkout feature/your-feature git fetch origin git merge origin/dev # Resolve conflicts in files # Then commit git add . git commit -m \u0026#34;Resolve merge conflicts\u0026#34; git push Repository Checklist Git initialized in project root .gitignore created with proper exclusions Initial commit created GitLab repository created Remote origin added Code pushed to GitLab Personal Access Token created (if needed) Files verified on GitLab Dev branch created Branch protection configured (optional) Next Steps "},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Continue learning and familiarizing yourself with AWS services Learn and implement projects Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Containerization with Docker - Container Orchestration with Amazon ECS - Container Orchestration with Amazon ECS 27/10/2025 27/10/2025 3 - CI/CD Pipeline with AWS CodePipeline - Automated Deployments with AWS CodePipeline - DevOps with AWS CodePipeline 28/10/2025 28/10/2025 https://cloudjourney.awsstudygroup.com/ 4 - Hybrid Storage with AWS Storage Gateway - Windows File Storage with Amazon FSx 29/10/2025 29/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Windows File Storage with Amazon FSx - Building Advanced Applications with Amazon DynamoDB 30/10/2025 30/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Workflow Orchestration with AWS Step Functions - Storage Performance Workshop 31/10/2025 31/10/2025 https://cloudjourney.awsstudygroup.com/ Week 8 Achievements: Containerization with Docker\nBuild and push Docker images for backend + frontend, deploy on EC2.\nCreate Docker network and launch containers, test applications via public IP.\nUse Docker Compose to manage stacks and redeploy the entire system quickly.\nContainer Orchestration with Amazon ECS\nUnderstand Amazon ECS architecture, create and manage ECS clusters.\nDefine ECS tasks and services, configure Application Load Balancer for load balancing.\nDeploy containerized applications on ECS, test deployment and clean up resources after completion.\nContainer Orchestration with Amazon ECS\nBuild containerized Spring Boot (Java 21) microservices and deploy to ECS Fargate.\nUse AWS CDK to create VPC + NAT Gateway, ECS Cluster, Load Balancer, and API Gateway.\nCreate DynamoDB using CDK to serve as a backend storage for service “products”.\nInstrument ECS service with AWS X‑Ray (add sidecar, declare Inspector, test trace).\nClean up resources after completing the workshop.\nCI/CD Pipeline with AWS CodePipeline\nSet up automated CI/CD for containers on Amazon ECS, using GitLab, GitHub or CodeBuild.\nDeploy integration workflow (build → deploy) to ECS Service, ensuring automatic application updates.\nMonitor containers with Container Insights + collect logs via FireLens, ensuring effective observation and debugging.\nClean up AWS resources after completion to optimize costs.\nAutomated Deployments with AWS CodePipeline\nSet up a CodePipeline pipeline integrating CodeCommit → CodeBuild → CodeDeploy to deploy Node.js applications to EC2.\nConfigure CodeDeploy Agent on EC2 (via Session Manager or User Data).\nDeploy the application in-place to EC2 instances, test after deployment.\nSet up infrastructure (VPC, Security Group, RDS if needed) to serve the pipeline.\nClean up AWS resources after completing the lab to save costs.\nDevOps with AWS CodePipeline\nCreate an IAM Role for CodeBuild to interact with the EKS cluster.\nConfigure aws-auth to allow CodeBuild to use kubectl with permissions on the cluster.\nSet up a CodePipeline pipeline using CloudFormation to automatically build + deploy sample services to EKS.\nTrigger new releases when changing code on GitHub → automatically update services on EKS.\nClean up all resources (deployment, stack, bucket) after the lab to avoid additional costs.\nHybrid Storage with AWS Storage Gateway\nCreate S3 bucket + initialize EC2 to use as Storage Gateway.\nConfigure AWS Storage Gateway, create SMB/NFS file share and mount on on-premises machine.\nSet up SMB access (guest) to share files from on-prem machine to S3.\nTest by creating files on mounted drive → files are synchronized to S3.\nClean up resources: delete Gateway, EC2, S3 bucket after completion.\nWindows File Storage with Amazon FSx\nDeploy FSx Windows File Server using CloudFormation in VPC.\nCreate and map SMB file shares on EC2 Windows, test with sample data.\nEnable shadow copies to save previous file versions \u0026amp; configure backup storage.\nEnable Continuous Access share to support HA for applications such as SQL Server.\nAdjust storage capacity and throughput according to needs; clean up resources after doing lab\nBuilding Advanced Applications with Amazon DynamoDB\nDo hands-on DynamoDB lab to understand the basics of querying, Streams, Global Tables and NoSQL data model.\nBuild advanced “design patterns” for DynamoDB (partitioning, GSI, adjacency list).\nDeploy global serverless applications with DynamoDB Global Tables.\nWorkflow Orchestration with AWS Step Functions\nDesign and implement state machine orchestration using Lambda: including task, branching (Choice) and parallel (Parallel).\nConfigure retry \u0026amp; catch errors when Lambda encounters problems for more sustainable workflow.\nUse token callback (waitForTaskToken) to allow pause/resume workflow.\nSet up debugging / logging, visualize workflow and clean up resources after lab completion Storage Performance Workshop\nInitialize resources via CloudFormation (EC2, Security Group) to run performance lab.\nOptimize S3 throughput, use parallel prefix, sync command, and upload multiple small files to increase TPS.\nOptimize EFS performance: configure IOPS, I/O size, multi-threading and choose appropriate performance mode.\nClean up resources after lab: delete S3 bucket, terminate EC2, delete CloudFormation stack.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/5-workshop/5.09-cleanup/","title":"Cleanup","tags":[],"description":"","content":"Overview When you complete the workshop and no longer want to continue using it, delete all resources to avoid incurring charges.\nWarning: This process cannot be undone. All data will be permanently deleted.\nResources to Delete OJT E-commerce project includes:\nStack Resources Monthly Cost MonitoringStack CloudWatch Dashboard, Alarms ~$1.50 FrontendStack S3, CloudFront ~$1.50 ApiStack API Gateway, 11 Lambda functions ~$2 DatabaseStack RDS SQL Server, Secrets Manager ~$15 AuthStack Cognito User Pool $0 StorageStack S3 Buckets ~$1.25 NetworkStack VPC, NAT Gateway ~$23 Total ~$44/month Cleanup Order Must delete in reverse order of deployment:\n1. MonitoringStack 2. FrontendStack 3. ApiStack 4. DatabaseStack 5. AuthStack 6. StorageStack 7. NetworkStack 8. CDK Bootstrap (optional) Step 1: Navigate to Infrastructure Directory cd D:\\AWS\\Src\\OJT\\OJT_infrastructure Step 2: Empty S3 Buckets S3 buckets must be emptied before deletion:\n# List all OJT buckets aws s3 ls | Select-String \u0026#34;ojt\u0026#34; # Empty Images bucket aws s3 rm s3://ojt-ecommerce-images-123456789012 --recursive # Empty Logs bucket aws s3 rm s3://ojt-ecommerce-logs-123456789012 --recursive # Empty Frontend bucket (if deployed) aws s3 rm s3://ojt-ecommerce-frontend-123456789012 --recursive Or use PowerShell script:\n# Get all OJT buckets and empty them $buckets = aws s3 ls | Select-String \u0026#34;ojt\u0026#34; | ForEach-Object { $_.ToString().Split()[-1] } foreach ($bucket in $buckets) { Write-Host \u0026#34;Emptying bucket: $bucket\u0026#34; -ForegroundColor Yellow aws s3 rm \u0026#34;s3://$bucket\u0026#34; --recursive Write-Host \u0026#34;Bucket emptied: $bucket\u0026#34; -ForegroundColor Green } Step 3: Delete CDK Stacks 3.1 Delete Monitoring Stack # Delete Monitoring stack npx cdk destroy OJT-MonitoringStack --force # Or with confirmation npx cdk destroy OJT-MonitoringStack # Type \u0026#39;y\u0026#39; to confirm 3.2 Delete Frontend Stack # Delete Frontend stack npx cdk destroy OJT-FrontendStack --force 3.3 Delete API Stack # Delete API stack (Lambda functions + API Gateway) npx cdk destroy OJT-ApiStack --force 3.4 Delete Database Stack # Delete Database stack (RDS SQL Server) # This takes 5-10 minutes npx cdk destroy OJT-DatabaseStack --force Note: RDS deletion creates a final snapshot by default.\n3.5 Delete Auth Stack # Delete Auth stack (Cognito) npx cdk destroy OJT-AuthStack --force 3.6 Delete Storage Stack # Delete Storage stack (S3 buckets) npx cdk destroy OJT-StorageStack --force 3.7 Delete Network Stack # Delete Network stack (VPC, NAT Gateway) # This takes 3-5 minutes npx cdk destroy OJT-NetworkStack --force Step 4: Delete All Stacks at Once (Alternative) # Delete all stacks in correct order npm run destroy # Or using CDK directly npx cdk destroy --all --force Expected output:\nOJT-MonitoringStack: destroying... OJT-MonitoringStack: destroyed OJT-FrontendStack: destroying... OJT-FrontendStack: destroyed OJT-ApiStack: destroying... OJT-ApiStack: destroyed OJT-DatabaseStack: destroying... OJT-DatabaseStack: destroyed OJT-AuthStack: destroying... OJT-AuthStack: destroyed OJT-StorageStack: destroying... OJT-StorageStack: destroyed OJT-NetworkStack: destroying... OJT-NetworkStack: destroyed Step 5: Verify All Stacks Deleted # List remaining stacks aws cloudformation list-stacks ` --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE ` --query \u0026#34;StackSummaries[?contains(StackName, \u0026#39;OJT\u0026#39;)].StackName\u0026#34; ` --output table # Should return empty or no OJT stacks Step 6: Delete CDK Bootstrap (Optional) ⚠️ Only do this if you\u0026rsquo;re done with CDK completely in this region:\n# Get CDK assets bucket name $BUCKET_NAME = aws s3 ls | Select-String \u0026#34;cdk-\u0026#34; | ForEach-Object { $_.ToString().Split()[-1] } # Empty CDK assets bucket aws s3 rm \u0026#34;s3://$BUCKET_NAME\u0026#34; --recursive # Delete CDK bootstrap stack aws cloudformation delete-stack --stack-name CDKToolkit # Wait for deletion aws cloudformation wait stack-delete-complete --stack-name CDKToolkit Write-Host \u0026#34;CDK Bootstrap deleted\u0026#34; -ForegroundColor Green Step 7: Verify Complete Cleanup 7.1 Check CloudFormation aws cloudformation list-stacks ` --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE ` | Select-String \u0026#34;OJT\u0026#34; # Should return nothing 7.2 Check S3 aws s3 ls | Select-String \u0026#34;ojt\u0026#34; # Should return nothing 7.3 Check Lambda aws lambda list-functions ` --query \u0026#34;Functions[?contains(FunctionName, \u0026#39;OJT\u0026#39;)].FunctionName\u0026#34; # Should return empty array 7.4 Check RDS aws rds describe-db-instances ` --query \u0026#34;DBInstances[?contains(DBInstanceIdentifier, \u0026#39;ojt\u0026#39;)].DBInstanceIdentifier\u0026#34; # Should return empty array 7.5 Check API Gateway aws apigateway get-rest-apis ` --query \u0026#34;items[?contains(name, \u0026#39;OJT\u0026#39;)].name\u0026#34; # Should return empty array 7.6 Check Cognito aws cognito-idp list-user-pools --max-results 10 ` --query \u0026#34;UserPools[?contains(Name, \u0026#39;OJT\u0026#39;)].Name\u0026#34; # Should return empty array 7.7 Check NAT Gateway aws ec2 describe-nat-gateways ` --filter \u0026#34;Name=state,Values=available\u0026#34; ` --query \u0026#34;NatGateways[].NatGatewayId\u0026#34; # Should not show OJT NAT Gateways Step 8: Delete RDS Snapshots (Optional) # List RDS snapshots aws rds describe-db-snapshots ` --query \u0026#34;DBSnapshots[?contains(DBSnapshotIdentifier, \u0026#39;ojt\u0026#39;)].DBSnapshotIdentifier\u0026#34; # Delete each snapshot aws rds delete-db-snapshot --db-snapshot-identifier ojt-database-final-snapshot Step 9: Delete CloudWatch Log Groups (Optional) # List log groups aws logs describe-log-groups ` --log-group-name-prefix /aws/lambda/OJT ` --query \u0026#34;logGroups[].logGroupName\u0026#34; # Delete each log group $logGroups = aws logs describe-log-groups ` --log-group-name-prefix /aws/lambda/OJT ` --query \u0026#34;logGroups[].logGroupName\u0026#34; ` --output text foreach ($logGroup in $logGroups.Split()) { Write-Host \u0026#34;Deleting log group: $logGroup\u0026#34; aws logs delete-log-group --log-group-name $logGroup } Cost After Cleanup Immediate:\nMost resources: $0/month RDS snapshots: ~$0.095/GB/month (if kept) After complete cleanup:\nEverything: $0/month Troubleshooting Cleanup Issue: S3 Bucket Deletion Fails # Force empty and delete aws s3 rb s3://bucket-name --force Issue: CloudFormation Stack Stuck in DELETE_IN_PROGRESS # Check stack events for errors aws cloudformation describe-stack-events ` --stack-name OJT-NetworkStack ` --max-items 10 # If stuck, wait or check for dependencies Issue: RDS Deletion Protection Enabled # Disable deletion protection aws rds modify-db-instance ` --db-instance-identifier ojt-database ` --no-deletion-protection ` --apply-immediately # Wait a few minutes, then retry delete Issue: VPC Has Dependencies # Check for remaining ENIs aws ec2 describe-network-interfaces ` --filters \u0026#34;Name=vpc-id,Values=vpc-xxxxxxxx\u0026#34; # Delete any remaining ENIs manually aws ec2 delete-network-interface --network-interface-id eni-xxxxxxxx Issue: NAT Gateway Still Exists # Delete NAT Gateway manually aws ec2 delete-nat-gateway --nat-gateway-id nat-xxxxxxxx # Release Elastic IP aws ec2 release-address --allocation-id eipalloc-xxxxxxxx Cleanup Checklist CDK Stacks MonitoringStack deleted FrontendStack deleted ApiStack deleted DatabaseStack deleted AuthStack deleted StorageStack deleted NetworkStack deleted AWS Resources All S3 buckets emptied and deleted No remaining Lambda functions No remaining RDS instances No remaining API Gateways No remaining Cognito User Pools No remaining NAT Gateways No remaining VPCs Optional Cleanup CDK Bootstrap deleted RDS snapshots deleted CloudWatch Log Groups deleted GitLab repository archived/deleted Verification CloudFormation shows no OJT stacks AWS Billing shows decreasing costs No unexpected charges Conclusion You have completed the OJT E-commerce workshop! You have learned:\nInfrastructure as Code with AWS CDK (TypeScript)\nServerless Architecture with Lambda and API Gateway\nRDS SQL Server database management\nVPC Design with public/private/isolated subnets\nS3 Storage for images and static files\nCloudFront CDN with Origin Access Control\nCognito Authentication (optional)\nJWT Authentication with custom Lambda\nCloudWatch Monitoring with dashboards and alarms\nCost Optimization strategies for serverless\nGitLab version control\n2-Step Deployment strategy (Infrastructure + Lambda code)\nTotal deployed:\n7 CDK stacks 11 Lambda modules (63 APIs) RDS SQL Server database VPC with NAT Gateway S3 buckets for storage CloudFront CDN CloudWatch monitoring Production-ready e-commerce platform Estimated monthly cost: ~$44/month (optimized)\nThank you for completing the workshop! 🎉\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives: Learn more about aws services Continue working on the project Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Serverless Backend with Lambda, S3, and DynamoDB - Frontend Development for Serverless APIs 03/11/2025 03/11/2025 3 - Deployment Automation with AWS SAM - User Authentication with Amazon Cognito 04/11/2025 04/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Custom Domains and SSL for Serverless Applications - Event Processing with SQS and SNS 05/11/2025 05/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - CI/CD for Serverless Applications - Monitoring Serverless Applications - Building GraphQL APIs with AWS AppSync 06/11/2025 06/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Building Serverless APIs - Serverless Chat Application 07/11/2025 07/11/2025 https://cloudjourney.awsstudygroup.com/ Week 9 Achievements: Frontend Development for Serverless APIs Build a web interface (frontend) to call API created by API Gateway + Lambda.\nDeploy front-end: can host static site (HTML/CSS/JS) connecting to serverless backend.\nDeploy Lambda function to handle request logic from API Gateway.\nConfigure API Gateway as endpoint for frontend: define route, HTTP method,…\nTest API with Postman: ensure API Gateway + Lambda runs correctly before frontend calls.\nTest frontend: web app calls API Gateway, receives results from Lambda and displays.\nDeployment Automation with AWS SAM Use AWS SAM (Serverless Application Model) to define serverless application via YAML file, then SAM will convert to CloudFormation when deploying.\nCreate and deploy front-end, Lambda function and API Gateway with SAM.\nTest API with Postman and frontend after deploying.\nUser Authentication with Amazon Cognito Create a Cognito User Pool to manage registration, login, email verification, password change, password reset.\nUse Identity Pool if you need to grant AWS Credentials (temporarily) to users to access services such as S3, DynamoDB.\nCreate API and Lambda: after the user authenticates via Cognito, Lambda handles the API request.\nFrontend: build login/registration UI, call Cognito API to log in and get token; then send token to API Gateway/Lambda.\nCustom Domains \u0026amp; SSL for Serverless Apps Use API Gateway to configure a custom domain name (“custom domain”) instead of the default hostname of API Gateway.\nUse Amazon Certificate Manager (ACM) to create or import SSL/TLS certificate for the domain, ensuring HTTPS.\nSelect custom domain type: edge-optimized (using CloudFront) or regional.\nConfigure Base Path Mapping to map domain + path to API Gateway stages.\nCreate DNS record (Route 53 or other DNS) to point domain to CloudFront distribution or endpoint provided by API Gateway.\nSSL and security: you can choose TLS security policy, ACM will manage certificate renewal. AWS Docs\n**Event Processing with SQS \u0026amp; SNS ** When users place an order, API sends messages to SQS queue to ensure “queue” to process the order.\nAt the same time, SNS is used to notify admin every time there is a new order.\nCreate Lambdas:\ncheckout_order to receive orders from API and push messages to SQS + publish SNS.\nhandle_order for admin to process orders: read from SQS, write orders to DynamoDB.\ndelete_order for admin to delete order: delete message in SQS.\norder_management for admin to view order list (using DynamoDB).\nArchitecture uses SQS for durability and asynchronous processing, SNS for fan-out notifications.\nCI/CD for Serverless Apps Use AWS SAM Pipelines to automate the process of building, packaging and deploying serverless applications.\nInitialize CI/CD pipeline: sam pipeline init to create pipeline configuration for AWS CodePipeline\nPipeline includes many stages: Source (Git), Build (using SAM CLI), Deploy (CloudFormation/SAM).\nUse build container image provided by AWS SAM to compile serverless app, helping reduce the effort of creating separate CI image.\nPipeline follows AWS best-practice pattern: supports multi-account, multi-region.\nMonitoring Serverless Applications Use CloudWatch Logs to debug Lambda: log invocations, errors, etc.\nCreate custom metrics in CloudWatch to monitor business or performance metrics.\nConfigure CloudWatch Alarms based on metrics to alert when there is an abnormal situation.\nUse AWS X-Ray to trace requests: draw service maps, see the path of requests and find bottlenecks.\n###Building GraphQL APIs with AWS AppSync\nUse AWS AppSync to create serverless GraphQL APIs, combined with AWS data sources such as DynamoDB, Lambda or Aurora Serverless.\nDefine GraphQL schema: type, query, mutation, subscription (if real-time required). AWS Docs\nConfigure resolvers:\nUse VTL mapping template to convert GraphQL requests into data source query operations.\nOr use Direct Lambda Resolver: Lambda handles GraphQL logic, avoiding the need to write VTL.\nIf using a relational database (Aurora Serverless), AppSync can connect via Data API to execute SQL commands via GraphQL mutation/query.\nAPI access can be managed in the following ways: AWS IAM, Cognito User Pools,… (authentication + authorization).\nBuilding Serverless APIs (Serverless with Lambda, API Gateway and SAM) Backend architecture uses Lambda, API Gateway, DynamoDB, S3, and Cognito.\nFrontend is a JavaScript application (Vue.js) hosted on S3 / Amplify.\nUse AWS SAM to define serverless resources and deploy backend (Lambda + API Gateway + DynamoDB)\nLambda reads / writes data from DynamoDB: for example, Lambda scans DynamoDB table to return list of “parks” (rides, attractions).\nDeploy API Gateway for frontend to call API; Lambda handles request logic.\nIn realtime: Lambda subscribes to SNS topic, saves information to DynamoDB, and forwards payload to IoT Core so frontend can receive real-time data.\nServerless Chat Application Build a serverless real-time chat application using API Gateway WebSocket, Lambda, and DynamoDB.\nWhen a client connects (“$connect”), Lambda stores the connection ID in DynamoDB.\nWhen a client disconnects (“$disconnect”), Lambda deletes the connection ID from DynamoDB.\nWhen a client sends a message (“sendmessage” route), Lambda reads the connection IDs from DynamoDB and uses the API Gateway Management API to broadcast the message to all connected clients.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand basic AWS services, how to use the console \u0026amp; CLI. Tasks to be carried out this week: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Elastic Beanstalk Workshop - Deploying Node.js Applications - CI/CD with Elastic Beanstalk and CDK Pipelines 10/11/2025 10/11/2025 3 - WordPress on AWS - WordPress Architecture on AWS - Running WordPress on Amazon EC2 11/11/2025 11/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Amazon ECS Workshop - Containerization with Amazon ECS and AWS Fargate - Infrastructure as Code for ECS with CDK - CI/CD Pipeline for ECS Applications 12/11/2025 12/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Machine Learning Essentials - Machine Learning with Amazon SageMaker - SageMaker Immersion Day 13/11/2025 13/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Data Lake - Data Lake Fundamentals on - Building a Data Lake with Your Own DataAWS 14/11/2025 14/11/2025 https://cloudjourney.awsstudygroup.com/ Week 10 Achievements: Elastic Beanstalk Workshop Deploying Node.js Applications with Elastic Beanstalk Deploy Node.js applications using Elastic Beanstalk to automate deployment, scaling, and application environment management.\nElastic Beanstalk supports Node.js platform, self-configuring EC2, load balancer, auto-scaling, and runtime environment.\nDeploy applications: use EB CLI (eb init, eb create, eb deploy) to package source code, create environment, and publish the app.\nEnvironment management: monitor logs, configure scaling, update version, and rollback when needed.\nCI/CD with Elastic Beanstalk and CDK Pipelines Set up automated CI/CD for applications using AWS CDK Pipelines and Elastic Beanstalk.\nCDK defines infrastructure: create Elastic Beanstalk Application, Environment, and Pipeline as IaC.\nPipeline: get source from repository, build application, create package and automatically deploy to Elastic Beanstalk every time there is a change in source code.\nDeployment: run cdk deploy for the first time to create pipeline; from then on, all code changes will be automatically built and updated to EB environment.\nExtendable support: can add more stages (dev/staging/prod), add test steps or pre-post-deploy authentication.\nWordPress on AWS WordPress Architecture on AWS Deploy WordPress on AWS in a multi-tier architecture to increase performance and scalability.\nWeb tier: run WordPress on EC2s in Auto Scaling Group, receive traffic via Application Load Balancer.\nDatabase: use RDS/Aurora MySQL to store WordPress data securely and sustainably.\nFile sharing: use EFS to share plugins, themes, uploads between multiple EC2s.\nStatic content: store images on S3 and distribute via CloudFront to reduce load and speed.\nCaching: integrate ElastiCache to optimize queries and reduce pressure on the database.\nRunning WordPress on Amazon EC2 Use Amazon EC2 to initialize a server (instance) — run web server + PHP + MySQL (or MariaDB) to host WordPress.\nMake sure the security group configuration allows HTTP (and if necessary HTTPS) for users to access the website from the Internet.\nInstall Apache (httpd), PHP + MySQL extension; download WordPress, unzip to the web root directory, configure the wp-config.php file to connect to the database.\nStart the web service + database; then access the public DNS/IP to run the WordPress installation script, set up the site.\nAmazon ECS Workshop Containerization with Amazon ECS and AWS Fargate Docker → package applications into containers (Docker images).\nAmazon ECS: container orchestration service — manage scheduling, scaling, and deployment of containers.\nAWS Fargate: serverless compute engine for containers — run containers without managing underlying servers/EC2s.\nCI/CD Pipeline for ECS Applications Using containers + registry: package applications into Docker images, push them to Amazon ECR. AWS Docs\nThe pipeline consists of the following main steps: Source → Build → Deploy. Source from Git repo (e.g., GitHub/CodeCommit), Build with AWS CodeBuild to create a Docker image, and then push the image to ECR.\nAWS Builder Center\nAfter the build, the pipeline deploys the new image to the ECS cluster: ECS pulls the image from ECR and re-runs the service/container (usually Fargate), ensuring automated deployment and minimal downtime.\nMachine Learning Essentials Machine Learning with Amazon SageMaker* Amazon SageMaker is a full-stack ML service on AWS that helps you build, train, and deploy ML/AI models without having to manage the infrastructure yourself.\nYou can use the SageMaker Studio integrated environment (IDE) to develop, process data, test, and deploy models.\nSageMaker supports the entire ML workflow — from data preparation, feature engineering, model training, hyper-parameter tuning, to deploying models into production.\nSageMaker Immersion Day SageMaker Immersion Day is a hands-on workshop for ML engineers / data scientists / developers who want to learn the end-to-end ML process with SageMaker: from data processing → feature-engineering → train → deploy model.\nThe main steps in the workshop: open an environment with SageMaker Studio, prepare dataset (upload to S3), feature-engineering, train \u0026amp; tune the model, then deploy the model \u0026amp; test inference.\nThe workshop provides both built-in algorithms and the ability to use custom models (bring-your-own-model), allowing you to try both basic ML and custom ML.\nData Lake Data Lake Fundamentals on AWS A Data Lake is a central repository for storing any data — structured, semi-structured, unstructured — at any scale, keeping the data “raw” without any pre-formatting.\nAWS uses Amazon S3 as the primary storage platform for your Data Lake — it’s simple, flexible, scalable, and integrates well with other analytics services.\nTo manage metadata and schemas, use AWS Glue (Glue Data Catalog, crawler) to “catalog” your data — making it easy to find, analyze, and share data across teams.\nBuilding a Data Lake with Your Data on AWS Storing raw data — uploading data (CSV, JSON, logs, etc.) to Amazon S3; S3 acts as the central repository for your data lake.\nUsing AWS Glue to crawl data: auto-discovern schema, table; create metadata/catalog for easy management \u0026amp; query.\nBuild serverless ETL/ELT pipeline: Glue processes ingest \u0026amp; transform data (from raw → cleaned/structured) before saving to S3 (can be in layers raw → refined → aggregated).\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Objectives: enter the Project sprint review the services to be used Tasks to be implemented this week: Day Task Start Date Completion Date Resources 2 - Hybrid DNS Management with Amazon Route53 17/11/2025 17/11/2025 3 - Building Serverless CRUD with Lambda and DynamoDB 18/11/2025 18/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Serverless Storage and Auth with AWS Amplify 19/11/2025 19/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - Frontend Integration with API Gateway 20/11/2025 20/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Network Integration with VPC Peering 21/11/2025 21/11/2025 https://cloudjourney.awsstudygroup.com/ Results achieved in week 11: I have studied and understood the above lessons and these are the difficulties when applying them to the project. Lambda + DynamoDB (Serverless CRUD) Design an API Gateway that is synchronized with FFF\u0026rsquo;s request/response.\nSeparate handlers, business logic, and error handling in Lambda to avoid confusing processing flows.\nSwitching from RDS to DynamoDB changes the data model (PK/SK, GSI).\nFFF data has many relationships → difficult to optimize DynamoDB without designing One-Table.\nDistributed logging + CloudWatch → complex debugging.\nConfigure IAM role to minimize permissions for Lambda to access DynamoDB.\nCORS, mapping template, stage variables of API Gateway are prone to errors.\nCI/CD from GitLab → Lambda needs automatic pipeline (zip code, deploy).\nOptimize cold start, timeout when traffic increases.\nSample CRUD logic is too simple → FFF needs multi-step workflow.\nAmplify Storage \u0026amp; Auth Amplify uses Cognito + S3, needs to synchronize with FFF backend (roles, session).\nMapping Cognito permissions (User Pool / Identity Pool) with RBAC FFF is complex.\nSynchronizing Amplify login with API Gateway IAM auth or JWT validator requires manual configuration.\nUpload files via Amplify Storage → S3 policy, read/write permissions by user type.\nUpload large files (images/videos) need presigned URL + security limits.\nAmplify CLI creates many auto resources → easily messes up CloudFormation stack.\nCI/CD with Amplify Hosting/Backend if combining GitLab is complicated.\nFrontend Integration with API Gateway Must clearly design endpoint URL, stage, mapping for frontend to connect Lambda/DynamoDB properly.\nConfigure CORS, headers, content-type so frontend fetch does not fail.\nHandle authentication/authorization on frontend: Cognito JWT, token refresh.\nUnified error handling: API returns error, frontend displays correct notification.\nManage versioning, stage environment: dev/staging/prod → avoid frontend calling wrong endpoint.\nOptimize performance: multiple concurrent requests → avoid API Gateway throttling.\nNetwork Integration with VPC Peering Set up VPC Peering between FFF VPCs and Lambda/DynamoDB services that need to be accessed.\nConfigure route tables, security groups, NACLs so that Lambda/API Gateway traffic goes to the correct VPC.\nControl DNS resolution between VPCs → avoid conflicts with private hosted zones.\nHandle latency and throughput when peering multiple VPCs → affect performance.\nSecurity control: only allow necessary IP/port, avoid exposing internal data.\nWhen expanding multi-account → peering is complicated, difficult to scale if there are many VPCs.\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12 Objectives: enter the Project sprint review the services to be used Tasks to be implemented this week: Day Task Start date Completion date Resources 2 - Database Essentials with Amazon Relational Database Service (RDS) 24/11/2025 24/11/2025 3 - Access Management with AWS Identity and Access Management (IAM) 25/11/2025 25/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Serverless Automation with AWS Lambda 26/11/2025 26/11/2025 https://cloudjourney.awsstudygroup.com/ 5 - AWS CDK Advanced 27/11/2025 27/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Application Protection with AWS WAF 28/11/2025 28/11/2025 https://cloudjourney.awsstudygroup.com/ Results achieved in week 12: Serverless, Amplify \u0026amp; Network Integration Challenges API Gateway synchronizes request/response, separate handler \u0026amp; business logic, clear error handling\nMove from RDS to DynamoDB: PK/SK, GSI, multi-relational data difficult to optimize One-Table\nDistributed logging CloudWatch → difficult to debug\nMinimum IAM role for Lambda, CORS/mapping template prone to errors\nCI/CD GitLab → deploy Lambda automatically, optimize cold start \u0026amp; timeout\nSimple CRUD → complex FFF workflow\nServerless Automation Challenges (AWS Lambda) Clearly separate handler, business logic, error handling to avoid confusing processing flow\nCold start, timeout when traffic is high\nDistributed logging via CloudWatch → difficult to debug\nMinimum IAM role for Lambda, ensure security\nCI/CD GitLab → Automatic Lambda deployment, zip code, versioning\nComplex workflow → Insufficient sample CRUD\nConnecting to DynamoDB, S3, API Gateway requires accurate mapping\nManaging concurrency, throttling when multiple requests are made simultaneously\nAWS CDK Advanced Challenges Designing complex IaC infrastructure, managing multiple service stacks (Lambda, RDS, DynamoDB, S3, API Gateway)\nDependency between stacks → deploying in the correct order, avoiding cyclic dependency errors\nComplex parameters, environment variables, context management\nVersioning, updating stack → avoiding downtime or data loss\nSecurity: IAM role/policy must be synchronized with CDK\nApplication Protection Challenges (AWS WAF) Designing rules against SQL injection, XSS, bot traffic suitable for FFF\nTuning rate-based rules to avoid false positives/blocking valid users\nCombining WAF with API Gateway, CloudFront, ALB → complex configuration\nLogging + monitoring via CloudWatch → difficult to debug blocked requests\nUpdate rules when FFF changes API/endpoint\n"},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://mrgoat-hellking.github.io/fcj-workshop-template/en/tags/","title":"Tags","tags":[],"description":"","content":""}]